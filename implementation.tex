\chapter{Implementation}
\label{implementation}
\epigraph{What I cannot create, I do not understand.}
{\textit{Richard Feynman, 1988}}

%%%CDR Has been shown to be NP-Complete to find a solution and NP-Hard to find an optimial one.
As presented in the previous chapter, the problem of evolving a component system was shown to be NP-Complete, and the problem of finding an optimal evolution was shown to be NP-Hard.
Therefore, to automate this complex evolution process it will require an efficient algorithm and implementation to not only find satisfiable solutions, but also optimal ones. 

%%%The efficiency of the implementation is important as the problem can combinatorially grow into a hard problem 
The efficiency of the implementations is necessary for many instances of CDR problems.
The goal of many component models is to have large amounts of components with support creating multiple versions of each component.
This directly makes the complexity of evolution grow in a combinatorial manner, making any ad-hoc or overly simple CDR implementation quickly overwhelmed.
The CDR algorithm should then be implemented to be robust and fast.

%%%Formally it resembles the SAT problem, which already has efficient implementations, and has been used to solve this problem
The formal representation of this problem was presented as a set of constraints that must all be satisfied in order for a component relationships and the user request to be fulfilled.
This structure closely resembles the Boolean Satisfiability Problem (SAT), which has fast, robust solver implementations that can be used.
This has been noticed by other researchers \citep{leberre2008,Mancinelli2006} 
and the use of SAT solvers to implement CDR in both academia \citep{abate2011} and industry \citep{leBerre2010} has become common.

%%%Finding the optimial solutions requires extensions to SAT solvers
The finding of an optimal solution though is difficult when using a ``pure'' SAT solver, as it cannot easily represent constraints relating to criteria. 
However, through extending the SAT solver implementations to also handle other types of constraints, such as pseudo Boolean constraints, optimisation becomes significantly easier.

%%%In this chapter\ldots
In this chapter the algorithms and implementation of CDR using SAT solvers extended with pseudo Boolean constraints, are discussed.
First the Davis-Putnam-Logemann-Loveland algorithm \citep{Davis1960, davis1962machine} and its extensions, which are the basis for many current SAT solvers, are described.
This will give a basic understanding of the internal workings of current SAT solvers.
The specific implementation of Eclipse P2 and P2CUDF by \cite{leBerre2010} is then described,
this is given as a comparison of a current technology used by CDR implementations.
Then the description of this research's CDR implementation, GJSolver, is given.
The specific reason for the necessary changes, the differences from other solutions, and the advantages to using it.
This also describes the process in which it was validated and compared against other solvers in the MISC 2011 competition.

\section{Boolean Satisfiability Solvers}
\label{impl.SAT}
Boolean satisfiability (SAT) is the problem of determining if the variables in a Boolean equation can be assigned in such a way that the equation returns true.
This problem was the first identified NP-Complete problem, meaning that no known algorithm exists that efficiently solves all instances of SAT problems.
It has been used previously in this thesis as a means in chapter \ref{formal} as a means of showing component evolution as being NP-Complete.
This also means that many proofs of NP-Completeness is through the reduction to SAT, and therefore many difficult problems have been expressed in the terms of a Boolean equation.
The benefit of this is that algorithms and implementations of programs that solve SAT problems have received significant attention and research to provide solutions to these various problems.
Taking advantage of these algorithms will help with the creation of a CDR implementation that can robustly evolve a component system.

%%%SAT solvers are used to solve many problems, creating a community dedicated to creating fast implenmenations
SAT solvers have been used in various domains to tackle problems such as electronic design automation \citep{Marques-Silva2000}, 
model verification \citep{dennis2006}, and, of course, component system evolution \citep{leBerre2010}.
These uses have caused a great need to create efficient solvers, and this has spawned a community dedicated to creating efficient implementation.
This community, creates and improves their solvers, 
and as a means of validating their creations, regularly compare them against one another in a series of competitions \footnote{http://www.satcompetition.org/}.
Using a competition for progress not only encourages the improvement of solvers for a particular problem set, but also general improvements to the algorithms and heuristics used. 

%%%In this section a common implementation of SAT solvers is discussed, the DPLL algorithm
In this section, first a brief definition of the SAT problem is described, this defines much of the terminology in this domain used in the description of algorithms and implementations. 
Then a short description of the DPLL algorithm is given, this algorithm is the basis of most current SAT solvers and therefore is required knowledge to discuss current implementations.
A common variant of the DPLL algorithm in current SAT algorithms is the alteration to become conflict driven,
this alteration is presented and discussed.
The extension of this algorithm with Pseudo-Boolean constraints is then described,
as this extension allows for more complicated optimisation problems to be represented.
Finally, other methods of solving SAT problems are briefly discussed to give a broader description of the domain. 

\subsection{The SAT Problem}
As described above, the goal of a SAT algorithm is to find whether a set of variables in a Boolean equation can be assigned values in such a way as to make the equation equal true.
A common representation of such a formula is in Conjunctive Normal Form (CNF), this is defined as a conjunction of clauses, 
where each clause is a conjunction of literals, e.g. $(a \vee b) \wedge (\neg b \vee c)$.

This CNF representation of a SAT problem can be defined as such:
\begin{defs}
An instance of a SAT problem is a set of Boolean variables $V$ and a formula which is a set of clauses $F$.
Each clause in $F$ is a set of literals, where a literal is a variable $v$ or its negation $\neg v$.
A set of literals is said to be consistent if for any variable $v$, the set does not contain both $v$ and its negation $\neg v$.
A solution to a SAT formula $F$ is a consistent set of literals $P$, such that for every clause in $c$ in $F$ there exists a literal in $c$ that is also in $P$.
If there exists a $P$ that is a solution of a SAT formula $F$ the problem is said to be satisfiable, otherwise it is unsatisfiable. 
\end{defs}

That is, a SAT problem can have the variable $\{a,b,c\}$ and the formula $\{c_1,c_2\}$, where clauses $c_1 = {a,b}$ and $c_2 = {\neg b, c}$.
A solution for this problem could be $\{a,\neg b,c\}$ as $a \in c_1$ and $\neg b \in c_2$.
However $\{a, \neg b, b\}$ is not because it is not consistent, and $\{a, b, \neg c\}$ is not because it does not contain a literal in $c_2$.  

This definition also follows some classical logic rules, such as literals and their negation can be defined as $\neg \neg v = v$.
This rule can be extended to sets of literals where given a set of literals $P$, $\neg P = [\neg v \mid v \in P]$.

\subsection{Davis-Putnam-Logemann-Loveland algorithm for SAT Solvers}
%%%A successful algorithm for solving SAT problems is the DPLL algorithm, here we describe it in overview
The Davis-Putnam-Logemann-Loveland (DPLL) algorithm \citep{Davis1960, davis1962machine} for solving SAT problems is a complete (meaning it will find a solution if one exists), 
backtracking-based search algorithm for SAT problems represented in conjunctive normal form (CNF).

It runs by assuming a variable from the Boolean formula is true by adding it to the set of literals $P$ then calling itself to find if this new assignment is a solution.
It first takes this new set of literals and calculates literals that are inferred, in a process called unit-propagation. 
If this new set of literals contains a contradiction then the assumption was incorrect and it returns false, and negates the assumption to continue searching.
However, if this assumption leads to a solution it then returns that it is satisfiable, as it has found a solution that satisfies the formula.

The DPLL algorithm in defined in figure \ref{impl.DPLL} as presented in \cite{dixon2004automating}:
\begin{figure}[h]
\begin{center}
\begin{alltt}
function DPLL(\(F, P\))
   P = unit-propagate(\(F, P\))
   if \(P\) contains a contradiction:
       then return UNSATISIFABLE;
   if \(P\) is a solution to \(F\):
       then return SATISFIABLE;
   \(l\) = decide\((P)\);
   if DPLL\((F, P \cup \{l\})\)
       return SATISFIABLE
   else
       return DPLL\((F, P \cup \{\neg l\})\);
\end{alltt}
  \caption{Recursive DPLL algorithm}
  \label{impl.DPLL}
\end{center}
\end{figure}

The first \verb+if+ branch of the DPLL algorithm finds if partial assignment $P$ is consistent, if it is not it returns \verb+UNSATISIFABLE+.
The second \verb+if+ branch determines if the assignment $P$ is a solution to $F$, this would end the search by returning \verb+SATISFIABLE+.
The \verb+unit-propagation+ function and the \verb+decide+ function are both described in the following sections. 

\subsubsection{Unit Propagation}
The first part of this function is the call to infer new literals given the current assignment, this is known as unit-propagation.
Given a possible assignment, a clause is called unit if the assignment does not contain one literal, and contains all of its other literals negation.
That is, given an assignment $P$ and a clause $c$ if $|c \backslash \neg P| = 1$, then $c$ is unit.
A unit literal is then defined given a unit clause as the literal $l$ where $ c \backslash \neg P = \{l\}$.

This notion of ``unit'' allows a literal to be inferred to be in the solution given a current assignment.
For instance, given a formula $\{c_1,c_2\}$, where $c_1 = {a,b}$ and $c_2 = {\neg b, c}$, and the assignment $\{\neg a\}$;
clause $c_1$ is unit and literal $b$ is unit as $c_1 \backslash \neg \{\neg a\} = c_1 \backslash\{ a\} = \{b\}$.
Through unit propagation, $b$ can be inferred to be in the solution, as it must be to make $c_1$ true.
Therefore the assignment is extended to $\{\neg a, b\}$.
This new assignment then makes $c_2$ unit, which through unit propagation infers the assignment be $\{\neg a, b, c\}$, and so on.

The process of unit propagation is further defined in figure \ref{impl.propagation}
\begin{figure}[htp]
\begin{center}
\begin{alltt}
unit-propagate(\(F, P\)):
    while P is consistent and there exists a \(c \in F\) that given \(P\) is unit:
        \(l\) = unit literal in \(c\)
        \(P\) = \(P \cup \{l\}\)
\end{alltt}
  \caption{Pseudo code of Unit Propagation}
  \label{impl.propagation}
\end{center}
\end{figure}

\subsubsection{Literal Order}
The function \verb+decide+ returns a literal that is not unit, nor whose negation is unit, i.e. given $l =$ \verb+decide+$(F)$, $\{l\} \not \in F$ and $\{\neg l\} \not \in F$.
This literal is then added to the formula and checked for satisfiability.
If the formula is not satisfiable, then the negation is added to the formula and checked for satisfiability.  
The order in which the variables from the formula are selected will have a great impact on the speed at which the algorithm finds the formula to be satisfiable or not.

\subsection{Advancements in SAT Solvers}
Though the DPLL algorithm is the basis of most modern SAT solvers, the actual implementations have been altered to increase efficiency.
Some changes are briefly described here, these include the use of conflict learning, backjumping, and watched literals.
This section should give a broad overview of the techniques used in current SAT solvers, 
in order to show that their application to problems like component evolution is justified. 

\subsubsection{Conflict Learning and Backjumping}
Conflict learning \citep{stallman1976} is a technique to cache previously tried sets of assignments in order to stop re-solving the same sub-problems.
This is accomplished through remembering the clauses which inferred literals through unit propagation, these clauses are also known as reasons.
These reasons are then used to derive a clause which prunes exactly the branches which created the conflict.
This process basically works by identifying the inconsistent variable (a variable both inferred to be true and false) 
then creating a new clause from the clauses that is the reason for them being inferred.
This new clause is derived by disjoining the two reason clauses and removing both the references to the inconsistent variable.
This process is defined in figure \ref{impl.clauselearning}. 

\begin{figure}[htp]
\begin{center}
$\begin{array}{c}
\{a_1,\ldots,a_k, l\} \\
\{b_1,\ldots,b_m,\neg l\}\\
\hline
\{a_1,\ldots,a_k, b_1,\ldots,b_m \}
\end{array}$
  \caption{Clause Learning Definition}
  \label{impl.clauselearning}
\end{center}
\end{figure}

For example, if the reason for the infered literal $a$ is clause $\{a, b\}$, and the reason for $\neg a$ is clause $\{\neg a, c\}$,
then a new clause derived is $\{b,c\}$.
This new clause is then added to the formula, which then stops the process from stepping through the branches which caused this exact conflict to occur again.

Backjumping \citep{Gaschnig1979} is the technique which determines how far to up the search tree to backtrack when a conflict is found.
The higher up the tree that the technique ``jumps'' up the greater reduction of the search space.
This algorithm typically depends on the clause created through conflict learning in modern solvers.
This uses the derived learnt clause to determine the point in the search at which can be jumped to.
The search is backtracked to the level where the learnt clause becomes unit, this can significantly improve the performance when solving problems.

More advanced methods of conflict learning occur by minimising the size of the learn clauses, as presented in \cite{sorensson2009}.
This research describes search methods that use other reason clauses to find smaller more succinct conflict clauses.
The smaller the clause the more of the search tree is pruned and the more levels are backjumped through the search.
Therefore, significant improvements to the efficiency of modern SAT solvers is gained through the use of such methods.


\subsubsection{Watched Literals}
As noted by studies into the efficiency of DPLL-based SAT solvers \citep{dixon2004automating}, unit propagation is where the bulk of the computation occurs.
Attempts to increase the efficiency of this task was initially to find better heuristics \cite{JamesMCrawford1996} for the literal order, to encourage cascades of unit propagation.
These attempts were shown to work well on random SAT problems but be less efficient for large structured problems \citep{dixon2004automating}.

It was noted that within unit propagation most of the time was spent on identifying the unit clauses.
The naive approach to this solution was to examine every clause, and then every literal in the clause to find if it is unit or not.
The idea of watched literals \citep{Madigan2001} was added so that instead of having the clauses examined, 
the clauses maintain an index of the necessary literals that when added to the partial solution the clause becomes unit.
This ``don't call us, we will call you'' function makes the function of finding unit clauses less dependent on the amount of clauses in the formula.

Advances on watched literals have occurred through algorithms to maintain the index of literals, like that presented in \cite{Moskewicz2001}.
Such algorithms enable larger formulae to be solved without necessary increasing the time to solve them.

\subsection{Pseudo-Boolean Extension of SAT Solvers}
%%%Optimisation of SAT solvers is typically done through extending their possible constraints to include Psuedo Boolean inequalities
This DPLL algorithm can easily be adapted to solve problems with other types of constraints, not only SAT constraints.
Through extending DPLL with such constraints, more problems can be expressed and solved.
A typical extension is through using pseudo-Boolean constraints \citep{dixon2004automating}, these constraints consist of a linear inequality over Boolean variables.
Through this extension the optimisation of problems like the evolution of component systems can be accomplished.

\subsubsection{Pseudo-Boolean Representation}
The pseudo-Boolean representation is defined as such

\begin{defs}
A pseudo-Boolean constraint is a linear inequality over Boolean literals $x_i$ of the form

$\sum a_i x_i \geq k$

with $x_1 \in \{0,1\}$ and fixed integers $a_i$ and $k$.
\end{defs}

That is, the constraint is formed by a list of literals $\langle x_1,\ldots,x_i \rangle$, a list of integers $\langle a_1,\ldots,a_i \rangle$ and an integer $k$.
If the literal $x_i$ resolves to true then in the constraint it is mapped to $1$, otherwise  if $x_i$ resolves to false it is resolved to $0$.
The product of all the mapped literals with their integer counterpart is then summed, and if greater than the value $k$ then the constraint is true. 

For example, a pseudo-Boolean constraint such that $\langle a, \neg b , c\rangle$ with integers $\langle 1, 2, 3\rangle$ and value $3$,
can be denoted as the inequality $1a + 2 \neg b + 3c \geq 3$.
For an assignment $\{a , \neg b, \neg c\}$, this equation would resolve to $1 + 2 + 0 \geq 3$, which is true therefore this assignment satisfies this constraint.

In practise, the inequality can be not only $\geq$, but also $\leq$.
Also as the values are integers on either side, by subtracting one from the left or right side the inequalities $>$ and $<$ can also be created.
This makes the use of these constraints much more versatile when representing problems.

Such constraints, can be translated into the standard CNF, but the original pseudo-Boolean representation has been shown to be exponentially more concise \citep{dixon2004automating}.
Also given the proper amendments to unit propagation and other algorithms (some of which is described in \cite{Sheini2006}), 
it can be faster to find solutions to problems represented in pseudo-Boolean constraints rather than their translated SAT constraints \citep{dixon2004automating}.
Both of these reasons give ample justification to use the pseudo-Boolean extension to DPLL when mapping the component evolution problem to a set of constraints. 
 
\subsection{MiniSat and SAT4J}
MiniSAT presented in \cite{een2003}, is a simple SAT solver implementation written in C, and designed for speed and extensibility.
It uses the DPLL based conflict driven algorithm as discussed above.
This solver has become popular and is the basis of many other SAT solvers due to its open source distribution.
This has also lead to a track in the 2011 SAT competitions\footnote{http://www.satcompetition.org/2011/} that deals with only altering MiniSAT to increase performance.
This means that MiniSAT has been repeatedly validated for performance by third parties across many difference SAT problems. 

SAT4J \citep{le2010sat4j} is a Java re-implementation, and extension, of MiniSAT in the Java programming language.
The extensions SAT4J makes to MniSAT include the ability to find solutions to pseudo-Boolean constraints.
SAT4J was developed in order to quickly test combinations of advancements in SAT solving technology.
This goal has created an easily modifiable and transparent implementation, able to be used in various circumstances.

\section{GJSolver}
%%%My Implementation, cut the fat, straight forward
Through the course of this research an implementation grew out of the need to have a modifiable base to experiment with component dependency resolution.
Other implementations of CDR where often component model specific, or involved difficult (or impossible) to modify code.
The CDR implementation created through this research is known as GJSolver, 
and is designed to solve CDR problems represented in CUDF with optimisation descriptions in Mancoosi format.

Given the context under which GJSolver was developed, the set of requirements that it was designed according to are briefly listed here:
\begin{enumerate}
  \item \textbf{Mancoosi International Competition Ready}: The MISC gives a set of standards to solve CUDF problems with criteria defined using the Mancoosi optimisation format.
  A goal of the GJSolver is to be entered in the MISC in order to be compared against other solvers, and be validated to show the implementation is correct.
  Following these standards ensures that the solver can be entered, and then competing can show the relative speed of the GJSolver implementation.
  This will ensure that GJSolver is a valid and efficient implementation. 
  \item \textbf{Anytime Algorithm}: Return a solution, even if it is not the optimal solution, within a predefined amount of time. 
  CDR problems can be large and complex, finding the ``best'' solution can be difficult. 
  This requirement ensures that the algorithm will return a solution in a practical time frame.
  \item \textbf{Easily Creatable Criteria}: The ability to quickly implement and test criteria in a manner that enables experimentation, will increase the speed of research.
\end{enumerate}

The implementation details in the GJSolver that relate to these requirements will be discussed in the 

\subsection{Mancoosi International Solver Competition}
Given a goal of the GJSolver implementation is to compete in the MISC, the interface and standards defined for this competition must be followed.
How the entered solvers are executed, what environment they are executed in, and the output required are all important aspects to the development of GJSolver.

%%%They are executed on the command line
The way in which the entered solvers are executed must be a standard allowing for the automation of the majority of the competition.
The entered solvers should be able to be executed on the command line with three arguments, \verb+cudfin+, \verb+cudfout+ and \verb+criteria+.
These arguments are defined as:
\begin{itemize}
  \item \verb+cudfin+: is a relative path to a CUDF document (as specified in section \ref{formal.cudf}) that describes the problem to be solver.
  \item \verb+cudfout+: is a relative path to a non-existent file which is created by the solver to output the solution
  \item \verb+criteria+: is a Mancoosi optimisation format (as described in section \ref{formal.mancoosioptimisationformat}) that describes the 
\end{itemize}
The format of the output to the file whose relative path is given in the \verb+cudfout+ argument is a sub set of CUDF.
This output is only the package name, version and installed properties of the package description stanzas of only the packages that are installed in the new system are required.
This removes the preamble and request stanza, also all superfluous package information to simplify and limit the size of the output.

%%%The environment POSIX, with 5minutes 1GB of memory
The environment in which the solver is executed is a virtual machine running a GNU/Linux system in a x86 architecture with 1GB of memory (RAM).
It contains a Java runtime environment, allowing the use of Java as a primary language.
The time in which the solver is allowed to run is 5 minutes, after this is will return a result of ABORT at which time the solver will be forcibly executed.
This time limit either ensures that your algorithm returns a result quickly or is an anytime algorithm, where it can be return a result when interrupted during the search.
The latter is the option that has been selected for GJSolver, and will be discussed in the next section.

\subsection{Anytime Algorithm}
As component system evolution is NP-Hard, the time required to find an optimal solution can be impractical.
For this reason, GJSolver will be implemented with an anytime algorithm at its core.
An anytime algorithm can return a valid solution to a problem if it is interrupted before it ends.
This interruption could be a user or some other stimuli from another source.
In the case of GJSolver, the interruption will be caused by an internal timer dedicated to ensure that the algorithm does not run in time exceeding the 5 minute deadline.

Such anytime algorithms therefore create a trade-off between time and optimality, where the more time that is set aside for the algorithm to run the more optimal the solution. 
They can also create inconsistent results, as any input may, on different runs, return many different possible solutions.
This means that if it is necessary to interrupt the algorithm, it is possible to return non-optimal solutions.
However, this is only if interuption is necessary, as GJSolver will encounter a wide range of difficult problems, 
it is difficult, or impossible, to judge beforehand if a problem will require the algorithm to be interrupted. 

\subsection{Expendable Criteria}
The ability to test and experiment with a wide range of possible criteria to use in CDR is a goal of this research.
This requirement is one which must be defined
To enable this, GJSolver must be developed in a modular enough manner in which the criteria can be extended, modified, and executed quickly.

\subsubsection{Component Evolution Mapping}

\subsubsection{Pseudo-Boolean Optimisation}
%%%Then through repeatedly finding a solution then adding a constraint to ensure the next solution is at least as good, the best solution is found

%%%Further optimisation can be made through quickly finding a satisfactory solution, this reduces the space in which to find a better solution

\subsubsection{Iterative Strengthening}
The algorithm known as iterative strengthening presented in \cite{calistri1994iterative} and \cite{le2010sat4j}, 
describes an anytime algorithm that iteratively finds better solutions.
This is done by first finding a solution, then iteratively adding constraints to the formula that ensure the next solution found will be better than the previous.
This continues until either the algorithm is interrupted by the formula is unsatisfiable, then taking the last found solution. 
This algorithm is defined in figure \ref{impl.strength}

\begin{figure}[htp]
\begin{center}
\begin{alltt}
find-solution(\(F\),strengthen):
    \(answer\) = DPLL(\(F\))
    if \(answer\) = UNSAT:
        return UNSAT
    do:
        \(model\) = \(answer\)
        \(constraints\) = strengthen(\(model\))
        \(F\) = \(F \cup constraints\)
        \(answer\) = DPLL(\(F\))
    while not interrupted() and \(answer\) != UNSAT
    return \(model\) 
\end{alltt}
  \caption{Pseudo code of Iterative Strengthening Algorithm}
  \label{impl.strength}
\end{center}
\end{figure}

Firstly in this algorithm the \verb+DPLL+ algorithm has been altered slightly by only taking the formula $F$ and returning a set of literals $model$ that satisfy $F$.
The second option is that DPLL returns \verb+UNSAT+

\subsection{Lexicographic Optimisation}
The basic iterative strengthening approach assumes that there is only one strengthen function.
This is not the case in the lexicographically ordered criteria of the component system evolution problem.

\begin{figure}[htp]
\begin{center}
\begin{alltt}
find-lex-solution(\(F\),criteria):
    \(answer\) = DPLL(\(F\))
    if \(answer\) = UNSAT:
        return UNSAT
    order = \(\langle \rangle\)
    do:
        current-criterion = criteria.pop()
        order = order.append(current-criterion.order()))
        updateorder(order)
        do:
            \(model\) = \(answer\)
            \(constraints\) = current-criterion.strengthen(\(model\))
            \(F\) = \(F \cup constraints\)
            \(answer\) = DPLL(\(F\))
        while not interrupted() and \(answer\) != UNSAT
        \(F\) = \(F \backslash constraints\)
        \(F\) = \(F \cup \) current-criterion.lock(\(model\))
    while not interrupted() and current-criterion != null
    return \(model\) 
\end{alltt}
  \caption{Pseudo code of the Lexicographic Iterative Strengthening Algorithm}
  \label{impl.strength}
\end{center}
\end{figure}

\subsection{Drawbacks of this Optimisation approach}
%%%There are a few drawbacks to this mapping;
%%%These simplifications are mostly necessary for this problem as it keeps the problem manageable,
%%%and including all aspects of our formal optimisation framework would be practically impossible

%%%The optimisation must be represented linearly
As noted in \cite{le_berre_dependency_2009} and \cite{leBerre2010} there is no easy solution to extending a SAT solver to handle non-linear constraints.

%%%Real numbers must be truncated to fit the integer representation. 

%%%Only one solutin can be chosen so product orders are randomly selected to a degree, this can be mitigated by having no stochastic elements in the algorithm

%%%No criterion can be of a partial order though through product composition the problem can be a partial order

%%%The only aggregation of numbers between integers is addition.

%%%It is too expencive to recalculate cardinalities for each component given a specific solution, therefore the cardinalities of a component should be solution independant

\subsection{Verification}
%%%We entered this solver into two Mancoosi MISC competitions

%%%In the first competition we had only partially implemented much of the functionality, so we did not expect great results.

%%%In some instances we where returing non optimal solutions, The bug where we had to add all package versions of all components. 

%%%These problems where fixed, through comparing the results we had gotten from the competition with those from other solvers.
%%%We created our own miny competition which we ran to also ensure that time limits where adhered to.

%%%In the second competition we had fully implemented the solver and this allowed us to enter all tracks with EXCELLENT results

%%%The paranoid track

%%%The trendy track

%%%The user track


\section{Other Methods}
This \cite{Stuckenholz2007} study looks at using boolean optimisation with branch and bound as a solution, as does \cite{Jenson2010a}.


\subsection{Integer Programming}
%%%Discussion of this method as the best MISC solver uses this, it has a very complex implementation
\subsection{SMT Solvers}
%%%SMT Solver, a slightly higher logic than SAT uses; it has to broad a definition when SAT suffices
\subsection{Constraint Solver}
%%%We could just use Prolog, like SMT I think it is too broad when there are good SAT solvers

