\chapter{Implementation}
\label{implementation}
\epigraph{What I cannot create, I do not understand.}
{\textit{Richard Feynman, 1988}}

%%%CDR Has been shown to be NP-Complete to find a solution and NP-Hard to find an optimial one.
As presented in the previous chapter, the problem of evolving a component system was shown to be NP-Complete, and the problem of finding an optimal evolution was shown to be NP-Hard.
Therefore, to automate this complex evolution process it will require an efficient algorithm and implementation to not only find satisfiable solutions, but also optimal ones. 

%%%The efficiency of the implementation is important as the problem can combinatorially grow into a hard problem 
The efficiency of the implementations is necessary for many instances of CDR problems.
The goal of many component models is to have large amounts of components with support creating multiple versions of each component.
This directly makes the complexity of evolution grow in a combinatorial manner, making any ad-hoc or overly simple CDR implementation quickly overwhelmed.
The CDR algorithm should then be implemented to be robust and fast.

%%%Formally it resembles the SAT problem, which already has efficient implementations, and has been used to solve this problem
The formal representation of this problem was presented as a set of constraints that must all be satisfied in order for a component relationships and the user request to be fulfilled.
This structure closely resembles the Boolean Satisfiability Problem (SAT), which has fast, robust solver implementations that can be used.
This has been noticed by other researchers \citep{leberre2008,Mancinelli2006} 
and the use of SAT solvers to implement CDR in both academia \citep{abate2011} and industry \citep{leBerre2010} has become common.

%%%Finding the optimial solutions requires extensions to SAT solvers
The finding of an optimal solution though is difficult when using a ``pure'' SAT solver, as it cannot easily represent constraints relating to criteria. 
However, through extending the SAT solver implementations to also handle other types of constraints, such as pseudo Boolean constraints, optimisation becomes significantly easier.

%%%In this chapter\ldots
In this chapter the algorithms and implementation of CDR using SAT solvers extended with pseudo Boolean constraints, are discussed.
First the Davis-Putnam-Logemann-Loveland algorithm \citep{Davis1960, davis1962machine} and its extensions, which are the basis for many current SAT solvers, are described.
This will give a basic understanding of the internal workings of current SAT solvers.
The specific implementation of Eclipse P2 and P2CUDF by \cite{leBerre2010} is then described,
this is given as a comparison of a current technology used by CDR implementations.
Then the description of this research's CDR implementation, GJSolver, is given.
The specific reason for the necessary changes, the differences from other solutions, and the advantages to using it.
This also describes the process in which it was validated and compared against other solvers in the MISC 2011 competition.

\section{Boolean Satisfiability Solvers}
\label{impl.SAT}
Boolean satisfiability (SAT) is the problem of determining if the variables in a Boolean equation can be assigned in such a way that the equation returns true.
This problem was the first identified NP-Complete problem, meaning that no known algorithm exists that efficiently solves all instances of SAT problems.
It has been used previously in this thesis as a means in chapter \ref{formal} as a means of showing component evolution as being NP-Complete.
This also means that many proofs of NP-Completeness is through the reduction to SAT, and therefore many difficult problems have been expressed in the terms of a Boolean equation.
The benefit of this is that algorithms and implementations of programs that solve SAT problems have received significant attention and research to provide solutions to these various problems.
Taking advantage of these algorithms will help with the creation of a CDR implementation that can robustly evolve a component system.

%%%SAT solvers are used to solve many problems, creating a community dedicated to creating fast implenmenations
SAT solvers have been used in various domains to tackle problems such as electronic design automation \citep{Marques-Silva2000}, 
model verification \citep{dennis2006}, and, of course, component system evolution \citep{leBerre2010}.
These uses have caused a great need to create efficient solvers, and this has spawned a community dedicated to creating efficient implementation.
This community, creates and improves their solvers, 
and as a means of validating their creations, regularly compare them against one another in a series of competitions \footnote{http://www.satcompetition.org/}.
Using a competition for progress not only encourages the improvement of solvers for a particular problem set, but also general improvements to the algorithms and heuristics used. 

%%%In this section a common implementation of SAT solvers is discussed, the DPLL algorithm
In this section, first a brief definition of the SAT problem is described, this defines much of the terminology in this domain used in the description of algorithms and implementations. 
Then a short description of the DPLL algorithm is given, this algorithm is the basis of most current SAT solvers and therefore is required knowledge to discuss current implementations.
A common variant of the DPLL algorithm in current SAT algorithms is the alteration to become conflict driven,
this alteration is presented and discussed.
The extension of this algorithm with Pseudo-Boolean constraints is then described,
as this extension allows for more complicated optimisation problems to be represented.
Finally, other methods of solving SAT problems are briefly discussed to give a broader description of the domain. 

\subsection{The SAT Problem}
As described above, the goal of a SAT algorithm is to find whether a set of variables in a Boolean equation can be assigned values in such a way as to make the equation equal true.
A common representation of such a formula is in Conjunctive Normal Form (CNF), this is defined as a conjunction of clauses, 
where each clause is a conjunction of literals, e.g. $(a \vee b) \wedge (\neg b \vee c)$.

This CNF representation of a SAT problem can be defined as such:
\begin{defs}
An instance of a SAT problem is a set of Boolean variables $V$ and a formula which is a set of clauses $F$.
Each clause in $F$ is a set of literals, where a literal is a variable $v$ or its negation $\neg v$.
A set of literals is said to be consistent if for any variable $v$, the set does not contain both $v$ and its negation $\neg v$.
A solution to a SAT formula $F$ is a consistent set of literals $P$, such that for every clause in $c$ in $F$ there exists a literal in $c$ that is also in $P$.
If there exists a $P$ that is a solution of a SAT formula $F$ the problem is said to be satisfiable, otherwise it is unsatisfiable. 
\end{defs}

That is, a SAT problem can have the variable $\{a,b,c\}$ and the formula $\{c_1,c_2\}$, where clauses $c_1 = {a,b}$ and $c_2 = {\neg b, c}$.
A solution for this problem could be $\{a,\neg b,c\}$ as $a \in c_1$ and $\neg b \in c_2$.
However $\{a, \neg b, b\}$ is not because it is not consistent, and $\{a, b, \neg c\}$ is not because it does not contain a literal in $c_2$.  

This definition also follows some classical logic rules, such as literals and their negation can be defined as $\neg \neg v = v$.
This rule can be extended to sets of literals where given a set of literals $P$, $\neg P = [\neg v \mid v \in P]$.

\subsection{Davis-Putnam-Logemann-Loveland algorithm for SAT Solvers}
%%%A successful algorithm for solving SAT problems is the DPLL algorithm, here we describe it in overview
The Davis-Putnam-Logemann-Loveland (DPLL) algorithm \citep{Davis1960, davis1962machine} for solving SAT problems is a complete (meaning it will find a solution if one exists), 
backtracking-based search algorithm for SAT problems represented in conjunctive normal form (CNF).

It runs by assuming a variable from the Boolean formula is true by adding it to the set of literals $P$ then calling itself to find if this new assignment is a solution.
It first takes this new set of literals and calculates literals that are inferred, in a process called unit-propagation. 
If this new set of literals contains a contradiction then the assumption was incorrect and it returns false, and negates the assumption to continue searching.
However, if this assumption leads to a solution it then returns that it is satisfiable, as it has found a solution that satisfies the formula.

The DPLL algorithm in defined in figure \ref{impl.DPLL} as presented in \cite{dixon2004automating}:
\begin{figure}[h]
\begin{center}
\begin{alltt}
function DPLL(\(F, P\))
   P = unit-propagate(\(F, P\))
   if \(P\) contains a contradiction:
       then return UNSATISIFABLE;
   if \(P\) is a solution to \(F\):
       then return SATISFIABLE;
   \(l\) = decide\((P)\);
   if DPLL\((F, P \cup \{l\})\)
       return SATISFIABLE
   else
       return DPLL\((F, P \cup \{\neg l\})\);
\end{alltt}
  \caption{Recursive DPLL algorithm}
  \label{impl.DPLL}
\end{center}
\end{figure}

The first \verb+if+ branch of the DPLL algorithm finds if partial assignment $P$ is consistent, if it is not it returns \verb+UNSATISIFABLE+.
The second \verb+if+ branch determines if the assignment $P$ is a solution to $F$, this would end the search by returning \verb+SATISFIABLE+.
The \verb+unit-propagation+ function and the \verb+decide+ function are both described in the following sections. 

\subsubsection{Unit Propagation}
The first part of this function is the call to infer new literals given the current assignment, this is known as unit-propagation.
Given a possible assignment, a clause is called unit if the assignment does not contain one literal, and contains all of its other literals negation.
That is, given an assignment $P$ and a clause $c$ if $|c \backslash \neg P| = 1$, then $c$ is unit.
A unit literal is then defined given a unit clause as the literal $l$ where $ c \backslash \neg P = \{l\}$.

This notion of ``unit'' allows a literal to be inferred to be in the solution given a current assignment.
For instance, given a formula $\{c_1,c_2\}$, where $c_1 = {a,b}$ and $c_2 = {\neg b, c}$, and the assignment $\{\neg a\}$;
clause $c_1$ is unit and literal $b$ is unit as $c_1 \backslash \neg \{\neg a\} = c_1 \backslash\{ a\} = \{b\}$.
Through unit propagation, $b$ can be inferred to be in the solution, as it must be to make $c_1$ true.
Therefore the assignment is extended to $\{\neg a, b\}$.
This new assignment then makes $c_2$ unit, which through unit propagation infers the assignment be $\{\neg a, b, c\}$, and so on.

The process of unit propagation is further defined in figure \ref{impl.propagation}
\begin{figure}[htp]
\begin{center}
\begin{alltt}
unit-propagate(\(F, P\)):
    while P is consistent and there exists a \(c \in F\) that given \(P\) is unit:
        \(l\) = unit literal in \(c\)
        \(P\) = \(P \cup \{l\}\)
\end{alltt}
  \caption{Pseudo code of Unit Propagation}
  \label{impl.propagation}
\end{center}
\end{figure}

\subsubsection{Literal Order}
The function \verb+decide+ returns a literal that is not unit, nor whose negation is unit, i.e. given $l =$ \verb+decide+$(F)$, $\{l\} \not \in F$ and $\{\neg l\} \not \in F$.
This literal is then added to the formula and checked for satisfiability.
If the formula is not satisfiable, then the negation is added to the formula and checked for satisfiability.  
The order in which the variables from the formula are selected will have a great impact on the speed at which the algorithm finds the formula to be satisfiable or not.

\subsection{Advancements in SAT Solvers}
Though the DPLL algorithm is the basis of most modern SAT solvers, the actual implementations have been altered to increase efficiency.
Some changes are briefly described here, these include the use of conflict learning, backjumping, and watched literals.
This section should give a broad overview of the techniques used in current SAT solvers, 
in order to show that their application to problems like component evolution is justified. 

\subsubsection{Conflict Learning and Backjumping}
Conflict learning \citep{stallman1976} is a technique to cache previously tried sets of assignments in order to stop re-solving the same sub-problems.
This is accomplished through remembering the clauses which inferred literals through unit propagation, these clauses are also known as reasons.
These reasons are then used to derive a clause which prunes exactly the branches which created the conflict.
This process basically works by identifying the inconsistent variable (a variable both inferred to be true and false) 
then creating a new clause from the clauses that is the reason for them being inferred.
This new clause is derived by disjoining the two reason clauses and removing both the references to the inconsistent variable.
This process is defined in figure \ref{impl.clauselearning}. 

\begin{figure}[htp]
\begin{center}
$\begin{array}{c}
\{a_1,\ldots,a_k, l\} \\
\{b_1,\ldots,b_m,\neg l\}\\
\hline
\{a_1,\ldots,a_k, b_1,\ldots,b_m \}
\end{array}$
  \caption{Clause Learning Definition}
  \label{impl.clauselearning}
\end{center}
\end{figure}

For example, if the reason for the infered literal $a$ is clause $\{a, b\}$, and the reason for $\neg a$ is clause $\{\neg a, c\}$,
then a new clause derived is $\{b,c\}$.
This new clause is then added to the formula, which then stops the process from stepping through the branches which caused this exact conflict to occur again.

Backjumping \citep{Gaschnig1979} is the technique which determines how far to up the search tree to backtrack when a conflict is found.
The higher up the tree that the technique ``jumps'' up the greater reduction of the search space.
This algorithm typically depends on the clause created through conflict learning in modern solvers.
This uses the derived learnt clause to determine the point in the search at which can be jumped to.
The search is backtracked to the level where the learnt clause becomes unit, this can significantly improve the performance when solving problems.

More advanced methods of conflict learning occur by minimising the size of the learn clauses, as presented in \cite{sorensson2009}.
This research describes search methods that use other reason clauses to find smaller more succinct conflict clauses.
The smaller the clause the more of the search tree is pruned and the more levels are backjumped through the search.
Therefore, significant improvements to the efficiency of modern SAT solvers is gained through the use of such methods.


\subsubsection{Watched Literals}
As noted by studies into the efficiency of DPLL-based SAT solvers \citep{dixon2004automating}, unit propagation is where the bulk of the computation occurs.
Attempts to increase the efficiency of this task was initially to find better heuristics \cite{JamesMCrawford1996} for the literal order, to encourage cascades of unit propagation.
These attempts were shown to work well on random SAT problems but be less efficient for large structured problems \citep{dixon2004automating}.

It was noted that within unit propagation most of the time was spent on identifying the unit clauses.
The naive approach to this solution was to examine every clause, and then every literal in the clause to find if it is unit or not.
The idea of watched literals \citep{Madigan2001} was added so that instead of having the clauses examined, 
the clauses maintain an index of the necessary literals that when added to the partial solution the clause becomes unit.
This ``don't call us, we will call you'' function makes the function of finding unit clauses less dependent on the amount of clauses in the formula.

Advances on watched literals have occurred through algorithms to maintain the index of literals, like that presented in \cite{Moskewicz2001}.
Such algorithms enable larger formulae to be solved without necessary increasing the time to solve them.

\subsection{Pseudo-Boolean Optimisation of SAT Solvers}
%%%Optimisation of SAT solvers is typically done through extending their possible constraints to include Psuedo Boolean inequalities
This DPLL algorithm can easily be adapted to solve problems with other types of constraints, not only SAT constraints.
Through extending DPLL with such constraints, more problems can be expressed and solved.
A typical extension is through using pseudo-Boolean constraints \citep{dixon2004automating}, these constraints consist of a linear inequality over Boolean variables.
Through this extension the optimisation of problems like the evolution of component systems can be accomplished.

\subsubsection{Pseudo-Boolean Representation}
The pseudo-Boolean representation is defined as such

\begin{defs}
A pseudo-Boolean constraint is a linear inequality over Boolean literals $x_i$ of the form

$\sum a_i x_i \geq k$

with $x_1 \in \{0,1\}$ and fixed integers $a_i$ and $k$.
\end{defs}

That is, the constraint is formed by a list of literals $\langle x_1,\ldots,x_i \rangle$, a list of integers $\langle a_1,\ldots,a_i \rangle$ and an integer $k$.
If the literal $x_i$ resolves to true then in the constraint it is mapped to $1$, otherwise  if $x_i$ resolves to false it is resolved to $0$.
The product of all the mapped literals with their integer counterpart is then summed, and if greater than the value $k$ then the constraint is true. 

For example, a pseudo-Boolean constraint such that $\langle a, \neg b , c\rangle$ with integers $\langle 1, 2, 3\rangle$ and value $3$,
can be denoted as the inequality $1a + 2 \neg b + 3c \geq 3$.
For an assignment $\{a , \neg b, \neg c\}$, this equation would resolve to $1 + 2 + 0 \geq 3$, which is true therefore this assignment satisfies this constraint.

In practise, the inequality can be not only $\geq$, but also $\leq$.
Also as the values are integers on either side, by subtracting one from the left or right side the inequalities $>$ and $<$ can also be created.
This makes the use of these constraints much more versatile when representing problems.

Such constraints, can be translated into the standard CNF, but have been shown to be exponentially more concise \citep{dixon2004automating}.
Also given the proper amendments to unit propagation and other algorithms (some of which is described in \cite{Sheini2006}), 
it can be faster to find solutions to problems represented in pseudo-Boolean constraints rather than their translated SAT constraints.
Both of these reasons give ample reason to use the pseudo-Boolean extension to DPLL when mapping the component evolution problem to a set of constraints. 

\subsubsection{Pseudo-Boolean Optimisation}
%%%Then through repeatdly finding a solution then adding a constraint to ensure the next solution is at least as good, the best solution is found

%%%Further optimisation can be made through quickly finding a satisfactory solution, this reduces the space in which to find a better solution

\subsection{MiniSat and SAT4J}
MiniSAT presented in \cite{een2003}, is a simple SAT solver implementation written in C, and designed for speed and extensibility.
SAT4J is a Java implementation, and extension, of that is used in a variety of domains as it is fast and thoroughly verified.
Both of these solvers use similar conflict driven DPLL algorithms presetned earlier, and thus are complete, fast and efficient solvers of SAT problems.
This can be seen, as both solvers have regularly been entered into SAT solving competitions, where their results are excellent.

\subsection{Other Methods}
This \cite{Stuckenholz2007} study looks at using boolean optimisation with branch and bound as a solution, as does \cite{Jenson2010a}.


\subsubsection{Integer Programming}
%%%Discussion of this method as the best MISC solver uses this, it has a very complex implementation
\subsubsection{SMT Solvers}
%%%SMT Solver, a slightly higher logic than SAT uses; it has to broad a definition when SAT suffices
\subsubsection{Constraint Solver}
%%%We could just use Prolog, like SMT I think it is too broad when there are good SAT solvers


\section{GJSolver}
%%%My Implementation, cut the fat, straight forward
Through the course of this research an implementation grew out of the need to have a modifiable base to experiment with component dependency resolution.
Other implementations of CDR where often platform specific, or involved difficult (or impossible) to modify code.
This CDR implementation is know as GJSolver, and is directly designed to solve CDR problems represented in CUDF, with optimisation descriptions in Mancoosi format.

SAT4J was used as a base for the satisfiability, where minor non-critical code was altered in order to interface with it correctly.

\subsection{Component Evolution Mapping}

\subsection{Lexicographic Optimisation Mapping}
%%%Here we descirbe the mapping from our Optimisation framework to PBO, product order is easy, lexicographic requires some muddling

\subsection{Drawbacks of this Optimisation approach}
%%%There are a few drawbacks to this mapping;
%%%These simplifications are mostly necessary for this problem as it keeps the problem manageable,
%%%and including all aspects of our formal optimisation framework would be practically impossible

%%%The optimisation must be represented linearly
As noted in \cite{le_berre_dependency_2009} and \cite{leBerre2010} there is no easy solution to extending a SAT solver to handle non-linear constraints.

%%%Real numbers must be truncated to fit the integer representation. 

%%%Only one solutin can be chosen so product orders are randomly selected to a degree, this can be mitigated by having no stochastic elements in the algorithm

%%%No criterion can be of a partial order though through product composition the problem can be a partial order

%%%The only aggregation of numbers between integers is addition.

%%%It is too expencive to recalculate cardinalities for each component given a specific solution, therefore the cardinalities of a component should be solution independant

\subsection{Verification}
%%%We entered this solver into two Mancoosi MISC competitions

%%%In the first competition we had only partially implemented much of the functionality, so we did not expect great results.

%%%In some instances we where returing non optimal solutions, The bug where we had to add all package versions of all components. 

%%%These problems where fixed, through comparing the results we had gotten from the competition with those from other solvers.
%%%We created our own miny competition which we ran to also ensure that time limits where adhered to.

%%%In the second competition we had fully implemented the solver and this allowed us to enter all tracks with EXCELLENT results

%%%The paranoid track

%%%The trendy track

%%%The user track




