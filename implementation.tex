\chapter{Resolving \modelname}
\label{implementation}
\epigraph{What I cannot create, I do not understand.}
{\textit{Richard Feynman, 1988}}

An instance of \modelname (presented in chapter \ref{formal}) describes the evolution of a component system.
Finding the component systems $\alpha_{t_0}$,\ldots,$\alpha_{t_n}$ of a \modelname instance (called \textbf{resolving}), however, requires significant calculation.

In this chapter \modelimpl is presented as a process that takes an instance of \modelname and resolves it.
\modelimpl maps evolution problems to SAT and pseudo-Boolean  (PB) \citep{dixon2004automating} problems and evolution preference orders as lexicographically ordered PB criteria.
Then by using the Davis-Putnam-Logemann-Loveland (DPLL) \citep{Davis1960, davis1962machine}
the iterative strengthening \citep{calistri1994iterative, le2010sat4j} algorithms,
and the novel lexicographic-iterative-strengthening algorithm, \modelimpl calculates the systems $\alpha_{t_0}$,\ldots,$\alpha_{t_n}$.
These relationships are presented in figure \ref{impl.modelsatdiagram}.

\begin{figure}[htp]
\begin{center}
\digraph[scale=0.5]{implsatgraph}{
rankdir=BT;
SAT [label=<<TABLE BORDER="0" CELLBORDER="1" CELLSPACING="5"><TR><TD WIDTH="150">SAT problem</TD></TR></TABLE>> shape=none];
subgraph {
rank=same;
PBCrit [label=<<TABLE BORDER="0" CELLBORDER="1" CELLSPACING="5"><TR><TD WIDTH="150">PB criteria</TD></TR></TABLE>> shape=none];
SATPB [label=<<TABLE BORDER="0" CELLBORDER="1" CELLSPACING="5"><TR><TD WIDTH="150">SATwPB problem</TD></TR></TABLE>> shape=none];
\modelnamewx [label=<<TABLE  BORDER="0" CELLBORDER="1" CELLSPACING="5"><TR><TD WIDTH="150">\modelnamewx</TD></TR></TABLE>> shape=none];
}
subgraph {
	rank=same
	\modelimplwx [label=<<TABLE  BORDER="0" CELLBORDER="1" CELLSPACING="5"><TR><TD WIDTH="150">\modelimplwx</TD></TR></TABLE>> shape=none ];
	FMI [label=<<TABLE BORDER="0" CELLBORDER="1" CELLSPACING="5"><TR><TD WIDTH="150">:\modelnamewx</TD></TR></TABLE>> shape=none ];
}
FMI -> \modelimplwx [ label="resolved by" ];
\modelimplwx -> PBCrit [label="uses" ];
SATPB -> SAT [label=extends];
FMI -> \modelnamewx [ label = "instantiates"];
\modelimplwx -> SATPB [label="uses" ];
}
  \caption[labelInTOC]{figureCaption}
  \label{impl.modelsatdiagram}
\end{center}
\end{figure}

GJSolver is the implementation of the process which takes a CUDF* document, maps to then resolves an instance of \modelname.
GJSolver was validated by entering the MISC competition created by Mancoosi, in which it competed and was compared against other solvers.

In this chapter firstly the mapping from a \modelname instance to a SAT and PB problem, and PB criteria is discussed in section \ref{impl.mapping}.
In section \ref{impl.algorithms}, the algorithms used to resolve an instance of \modelname are described.
Finally, in section \ref{impl.gjsolver} GJSolver is discussed, and its verification through the the Mancoosi International Solver Competition (MISC) is described.

\section{Formal Mapping to \modelimpl}
\label{impl.mapping}
\modelimpl takes an instance of \modelname and calculates the systems $\alpha_{t_0}$,\ldots,$\alpha_{t_n}$.
The first requirement of \modelimpl is to turn the instance into a problem that can be efficiently solved.
The Boolean satisfiability problem (SAT) problem, extended with pseudo-Boolean criteria, has been selected to represent evolution problems.
This was selected as it has been used within this domain previously \citep{leBerre2010}, and has many efficient solvers readily available.
Additionally, tuples of pseudo-Boolean criteria are used to represent the evolution preference order.
Together, the SAT and PB problem with PB criteria are used to resolve \modelname instances.

In this section, the SAT problem is presented and extended to include pseudo-Boolean constraints, and PB criteria are discussed. 
Then the mapping of an evolution problem to a SAT with PB problems, and an evolution preference order to PB criteria is described. 

\subsection{Boolean Satisfiability Problem}
Boolean satisfiability (SAT) is the problem of determining if the variables in a Boolean equation can be assigned in such a way that the equation returns true.
SAT was the first identified NP-Complete problem, meaning there is no known algorithm that efficiently solves all instances of SAT problems.
The fundamental difficulty of SAT problems, 
combined with the ability to map many problems to SAT has spawned a community\footnote{http://www.satcompetition.org/ accessed 6/3/2012} 
dedicated to creating, enhancing, and testing various SAT solver implementations. 
Such SAT solvers have been used in various domains to tackle problems such as electronic design automation \citep{Marques-Silva2000}, 
model verification \citep{dennis2006}, and, component system evolution \citep{leBerre2010}.

A common representation of a SAT equation is in Conjunctive Normal Form (CNF).
CNF is defined as a conjunction of clauses, 
where each clause is a disjunction of literals, e.g. $(a \vee b) \wedge (\neg b \vee c)$.

A SAT problem in CNF is defined as:
\begin{defs}
\label{impl.defSAT}
{\ }
\begin{enumerate}
    \item Let $V$ be a set of variables
    \item A \textbf{literal} is a variable $v$ or its negation $\neg v$.
    \item A literal $\neg \neg v \equiv v$
    \item Given a set of literals $P$, $\neg P \equiv \{\neg v \mid v \in P\}$
    \item A \textbf{clause} is a set of literals 
    \item A \textbf{formula} is a set of clauses \label{impl.whatisaformula}
    \item An instance of a \textbf{SAT problem} is a set of variables $V$ and a formula $F$
    \item A set of literals is \textbf{consistent} if for any variable $v$, the set of literals does not contain both $v$ and its negation $\neg v$.
    \item A clause $\mathcal{C}$ is \textbf{satisfied} by a set of literals $P$ if there exists a literal in $\mathcal{C}$ that is also in $P$.
    \item A \textbf{solution} to a formula $F$ is a consistent set of literals $P$, such that for every clause $\mathcal{C}$ in $F$, $\mathcal{C}$ is satisfied by $P$.
    \item A \textbf{partial solution} to $F$ is a subset of any solution, i.e. given $P$ is a solution, $P'$ is a partial solution iff $P' \subseteq P$.
    \item An instance of a SAT problem is \textbf{satisfiable} if there exists a set of literals $P$ that is a solution to $F$, otherwise the instance of the SAT problem is \textbf{unsatisfiable}. 
\end{enumerate}
\end{defs}

Assume a SAT problem where $V = \{a,b,c\}$ and $F = \{\mathcal{C}_1,\mathcal{C}_2\}$, where clauses $\mathcal{C}_1 = {a,b}$ and $\mathcal{C}_2 = {\neg b, c}$.
A solution for this problem could be $\{a,\neg b,c\}$ as $a \in \mathcal{C}_1$ and $\neg b \in \mathcal{C}_2$.
However, $\{a, \neg b, b\}$ is not a solution because it is not consistent, and $\{a, b, \neg c\}$ is not a solution because it does not contain a literal in $\mathcal{C}_2$.  


\subsubsection{Pseudo-Boolean Extension of SAT}
A typical extension of the SAT problem is where a clause in a CNF formula can be a pseudo-Boolean (PB) constraint \citep{dixon2004automating}.
PB constraints consist of a linear relation over Boolean variables.

A pseudo-Boolean function takes a set of Boolean literals and returns an integer, e.g. given a set of literals $P$, $f(P) = 4$.
\begin{defs}
\label{impl.PBfunction}
Given a tuple of literals $\langle l_1,\ldots,l_n \rangle$ and a tuple of integers $\langle a_1,\ldots,a_n\rangle$,
a \textbf{pseudo-Boolean function} takes a set of literals $P$, and returns an integer such that:

$f(P) = \sum \limits_{i=0}^n f_i(P)$
where $f_i(P) = \begin{cases} a_i & l_i \in P \\ 0 & l_i \not \in P \end{cases}$
\end{defs}
For example, the pseudo-Boolean function $f$ defined with a tuple of literals $\langle x_1, \neg x_2\rangle$ and a tuple of integers $\langle 1,3\rangle$,
 $f(\{x_1, x_2\})$ will equal $1$.

A pseudo-Boolean constraint is a relation between a the function and a number, e.g. given a set of literals $P$, $f(P) \leq 3$.
\begin{defs}
\label{impl.PBConstraint}
A \textbf{pseudo-Boolean constraint} is a tuple of a pseudo-Boolean function $f$, a relationship  $R$ in $\{\geq,>,\leq,<,=\}$, and an integer $k$, i.e. $\langle f,R,k\rangle$.
\end{defs}

\begin{defs}
A pseudo-Boolean constraint $\langle f,R,k\rangle$ is \textbf{satisfied} by a set of literals $P$ iff $ f(P) R k$.
\end{defs}
For example, the pseudo-Boolean $f$ described in the above example can be used to create the constraint $\langle f, >, 2 \rangle$.  
This constraint will be satisfied by the set of literals $P_1 = \{ x_1, \neg x_2 \}$ as $f(P_1) = 4 > 2$, but not with the set of literals $P_2 = \{ x_1,  x_2 \}$ as $f(P_2) = 1 \not > 2$.

Pseudo-Boolean constraints can be included in the above defined SAT problem by first adding the definition of what a PB constraint is, and what satisfies a PB constraint:
\begin{defs}
{\ }
\begin{enumerate}
\setcounter{enumi}{12}
  \item A \textbf{pseudo-Boolean constraint} is a tuple of a pseudo-Boolean function $f$, a relation $R$ in $\{\geq,>,\leq,<,=\}$, and a number $k$, i.e. $\langle f,R,k\rangle$.
  \item A pseudo-Boolean constraint $\langle f,R,k\rangle$ is \textbf{satisfied} by a set of literals $P$ iff $ f(P) R k$.
\end{enumerate}
\end{defs}

Second, by modifying the definition of what a formula can contain and what a solution to it is:
\begin{defs}
{\ }
\begin{enumerate}
\setcounter{enumi}{5}
    \item A \textbf{formula} is a set of clauses and pseudo-Boolean constraints
\end{enumerate}
\begin{enumerate}
\setcounter{enumi}{9}
    \item A \textbf{solution} to a formula $F$ is a consistent set of literals $P$, such that for every clause $\mathcal{C}$ in $F$, $\mathcal{C}$ is satisfied by $P$,
    and for every pseudo-Boolean constraint $pb$ in $F$, $pb$ is satisfied by $P$. 
\end{enumerate}
\end{defs}

Pseudo-Boolean constraints, can be translated into CNF clauses, but the original pseudo-Boolean representation has been shown to be exponentially more concise \citep{dixon2004automating}.
Given the proper amendments to algorithms that solve SAT problems (some of which are described in \citep{Sheini2006}), 
it can be faster to find solutions to problems represented in pseudo-Boolean constraints rather than their translated SAT constraints \citep{dixon2004automating}.
Both of these reasons give ample justification to use the pseudo-Boolean extension to SAT when mapping the component evolution problem to a set of constraints. 

\subsubsection{Pseudo-Boolean Criteria}
A SAT problem can have many different solutions, where some are more optimal than others.
Pseudo-Boolean criteria are used to define what an optimal solution to a SAT problem is. 

\begin{defs}
A \textbf{pseudo-Boolean criterion} $\mathfrak{crit}$ is a tuple consisting of a pseudo-Boolean function $f$,
a relation over integers $R$ that is either $<$ or $>$, and a SAT formula $I$ (as defined in \ref{impl.defSAT}),
i.e. $\mathfrak{crit} = \langle f, R , I \rangle$.
\end{defs}
The formula $I$ is used to define the auxiliary variables that are used to represent values within the problem, but do not alter the problem.
Auxiliary variables have been used before in similar implementations \citep{argelich2010solving}.

\begin{defs}
Given a formula $F$, and a pseudo-Boolean criterion $\langle f, R , I \rangle$, 
a solution $P$ to $F$ is optimal iff there exists no other solution $P'$ to $F$ such that $f(P') R f(P)$. 
\end{defs}


\subsection{Mapping SAT from an insstance of \modelname}
An instance of \modelname contains:
\begin{itemize}
  \item a series of times $t_0,\ldots,t_n$.
  \item sets of components $\mathbb{C}_{t_0},\ldots,\mathbb{C}_{t_n}$.
  \item sets of user requests $\delta_{t_1},\ldots,\delta_{t_n}$.
  \item sets of system constraints $\omega_{t_1},\ldots,\omega_{t_n}$.
  \item evolution preference orders $\prec_{\alpha_{t_0}},\ldots, \prec_{\alpha_{t_{n-1}}}$.
  \item initial system $\alpha_{t_0}$.
\end{itemize}
At each time $t_i$ in $t_1,\ldots,t_n$, the set of components $\mathbb{C}_{t_i}$ is mapped to a set of variables,
the component system  $\alpha_{t_{i-1}}$ is mapped to a set of literals,
the evolution problem $\delta_{t_i} \cup \omega_{t_i}$ is mapped to a SAT formula,
and the evolution preference order $\prec_{\alpha_{t_{i-1}}}$ is mapped to a tuple of PB criteria.


\begin{defs}
A set of components $\mathbb{C}_{t_i}$ is to a subset of the variables , i.e $\mathbb{C}_{t_i} \subseteq V_{t_i}$.
\end{defs}
This means that all components are variables, though there can be auxiliary variables that are not components.

\begin{defs}
  \item A component system $\alpha_{t_{i-1}}$ is mapped to a set of literals where
   $\alpha_{t_{i-1}} := \alpha_{t_{i-1}} \cup \{\neg c \mid c \in \mathbb{C}_{t_i}$ and $ c \not \in \alpha_{t_{i-1}}\}$.
\end{defs}
A component system $\alpha_{t_{i-1}}$ is mapped to a set of literals that is the union of $\alpha_{t_{i-1}}$ and the set of negative literals of components not in $\alpha_{t_{i-1}}$.

The reverse mapping, from a set of literals to a component system is:
\begin{defs}
A set of literals $P$ is mapped to a component system $\beta$ such that $\beta := \{c \mid c \in \mathbb{C}_t$ and $x \in P\}$
\end{defs}
A component system is the set of components that are not negative in the set of literals.  
Note: the mapping from literals to components is surjective, and the mapping from components to literals is injective.

The evolution problem is a set of constraints that are limited to five different types.
Each type of constraint can be mapped to a SAT clause or PB constraint:
\begin{enumerate}
  \item \textbf{Exclusion}: $\neg a := \{\neg a\}$
  \item \textbf{Conflict}: $a \rightarrow \neg c := \{\neg a, \neg c\}$ 
  \item \textbf{Inclusive Disjunction}: $a_1 \vee \ldots \vee a_n := \{a_1, \ldots,  a_n\}$ 
  \item \textbf{Dependence}: $a \rightarrow c_1 \vee \ldots \vee c_n := \{\neg a, c_1, \ldots, c_n\}$
  \item \textbf{Exactly One}: $a_1 + \ldots + a_n = 1 := $ a pseudo-Boolean constraint $\langle f,=, 1 \rangle$, 
  where $f$ is defined with the tuple of literals $\langle a_1 ,\ldots , a_n\rangle$ and the tuple of natural numbers $\langle 1_1,\ldots,1_n \rangle$.
\end{enumerate}

\begin{defs}
The evolution problem $\delta_{t_i} \cup \omega_{t_i}$ is mapped to the formula $F_{t_i}$, by mapping all constraints in $\delta_{t_i} \cup \omega_{t_i}$ to SAT clauses or PB constraints.
\end{defs}

\subsubsection{Evolution Preference Order Mapping}
The evolution preference order $\prec_{\alpha_{t_{i-1}}}$ defined with a lexicographic composition of criteria $crit_{1} \oplus \ldots \oplus crit_{n}$ 
can be mapped to a tuple of PB criteria $\langle \mathfrak{crit}_1,\ldots,\mathfrak{crit}_n\rangle$.

A criterion $\langle rank_{\alpha} ,\leq \rangle$ maps to a PB criteria $\langle f, R , I \rangle$ iff:
\begin{itemize}
  \item $R$ must equal $\leq$.
  \item given a solution to $I$ $P$ maps to the component system $\beta$, $f(P) = rank_{\alpha}(\beta)$. 
\end{itemize} 

Given the evolution preference order must be created from lexicographically composed criteria,
and not all criteria can be mapped to PB criteria, only a partial mapping of evolution preference orders in \modelname can be mapped to PB criteria tuples.
Of the criteria that can be mapped, generalizing their mapping may be a difficult and unrewarding challenge.
This is because many of the criteria that can be defined are not desirable or inane, e.g. maximising the number of components whose name starts with the letter \texttt{a}.
Therefore, only specific set of criteria are mapped from \modelname to \modelimpl.
These criteria are presented in chapter \ref{strategies}. 


\paragraph{Example}
To further describe the mapping from a criterion to a PB criteria, an example is presented.
Consider two components $a$ and $b$, a criterion $\langle rank_{\alpha},< \rangle$, whose ranking function $rank_{\alpha}$ is defined:

$rank_{\alpha}(\beta) = \begin{cases} 1 & a \in \beta \text{ or } b \in \beta\\ 0 & \text{otherwise} \end{cases}$

This criteria expresses the preference of having either components $a$ or $b$ (or both) in the system.

Further consider the pseudo-Boolean criterion $\langle f, < , I \rangle$.
The auxiliary variable $x$ is defined such that $x \Leftrightarrow a \in \beta \vee b \in \beta$.
This variable must be  converted to the set of CNF clauses, and included in $I$,
i.e. $I = \{\{\neg x, a,b\}, \{\neg a,x\}, \{\neg b, x \}\}$.
The PB function $f$ is defined with the tuple of literals $\langle x \rangle$ and natural numbers $\langle 1 \rangle$.

The criterion $\langle rank_{\alpha},< \rangle$ maps to $\langle f, < , I \rangle$,
as the relationship from the criterion equals the relationship from the PB criterion;
given a solution to $I$ $P$ maps to the component system $\beta$, $f(P) = rank_{\alpha}(\beta)$. 
This can is shown in table \ref{impl.critmapexmp}.
\begin{table}[h!]
\centering
\begin{tabular}{| c | c | c | c |}
\hline
$P$                                &    $\beta$            & $rank_{\alpha}(\beta)$     & $f(P)$\\ \hline    
$\{\neg a, \neg b, \neg x\}$     & $\{\}$                & 0                        & 0 \\
$\{\neg a,  b, x\}$             & $\{b\}$                & 1                        & 1 \\
$\{ a,  \neg b, x\}$             & $\{a\}$                & 1                        & 1 \\
$\{ a,  b, x\}$                 & $\{a,b\}$                & 1                        & 1 \\ \hline
\end{tabular}
\caption{Values to show $f_{\alpha}$  maps to $rank_{\alpha}$}
\label{impl.critmapexmp}
\end{table}


\section{Resolving a \modelname instance}
\label{impl.algorithms}
Above the formal model of an evolution problem is mapped to a SAT problem, 
and the lexicographically composed criteria that describe the evolution preference order are mapped to a tuple of pseudo-Boolean criteria.
In this section, a description is given of the algorithms used to find an optimal solution to a SAT problem given a tuple of pseudo-Boolean criteria. 

\subsection{Davis-Putnam-Logemann-Loveland algorithm for SAT Solvers}
%%%A successful algorithm for solving SAT problems is the DPLL algorithm, here we describe it in overview
The Davis-Putnam-Logemann-Loveland (DPLL) algorithm \citep{Davis1960, davis1962machine} for solving SAT problems is a complete (meaning it will find a solution if one exists), 
backtracking-based search algorithm for SAT problems represented in conjunctive normal form (CNF).

It is defined to take a formula $F$ and a set of literals $P$ (described as a partial assignment), and return \verb+SATISFIABLE+ if $P$ is a partial solution, 
otherwise returning \verb+UNSATISIFABLE+.
When \texttt{DPLL} is called without a value $P$, $P$ is defaulted to equal the empty set $\emptyset$.
By first calling \texttt{DPLL} with $P$ being the empty set, by adding literals to $P$, then recursively calling itself; 
the DPLL function searches for whether a solution to the formula exists, 
i.e the formula is satisfiable.
The DPLL algorithm in defined in figure \ref{impl.DPLL} (a slight modification of the algorithm presented in \citep{dixon2004automating}):
\begin{figure}[h]
\begin{center}
\begin{alltt}
function DPLL(\(F, P\))
   P = unit-propagate(\(F, P\))
   if \(P\) is not consistent:
       then return UNSATISIFABLE;
   if \(P\) is a solution to \(F\):
       then return \(P\);
   \(l\) = decide\((P)\);
   if DPLL\((F, P \cup \{l\})\) != UNSATISIFABLE 
       return DPLL\((F, P \cup \{l\})\)
   else
       return DPLL\((F, P \cup \{\neg l\})\);
\end{alltt}
  \caption{Recursive DPLL algorithm}
  \label{impl.DPLL}
\end{center}
\end{figure}

The first function call to \texttt{unit-propagation} derives additional literals that are added to the partial assignment $P$ (this function is discussed later in section \ref{impl.unit}).
The \verb+if+ branch returns \texttt{UNSATISIFABLE} if the partial assignment $P$ is inconsistent.
The second \verb+if+ branch determines if the partial assignment $P$ is a solution to $F$, this would end the search by returning the solution $P$.
The \texttt{decide} function returns a literal $l$ that is not in $P$, nor whose negation $\neg l$ is in $P$ (this function is discussed later in section \ref{impl.litorder}).
The search is then continued by adding the literal $l$ to $P$ and checking if that is a partial solution using \texttt{DPLL}.
If the partial assignment $P$ with $l$ is a is a partial solution, then \texttt{DPLL} does not equal \texttt{UNSATISIFABLE} and the found solution is returned.
However, if $P$ with $l$ is not a partial solution, then $P$ with $\neg l$ is checked to be a partial solution.

\subsubsection{Unit Propagation}
\label{impl.unit}
The first line in the  DPLL algorithm calls the \texttt{unit-propagation} function.
This function uses the clauses in the formula, and the partial assignment to identify and add literals to $P$ that must be included if $P$ is to be a partial solution.

\begin{defs}
Given a partial assignment $P$, a clause $\mathcal{C}$ is called \textbf{unit} iff $\mathcal{C}$ is not satisfied by $P$, and $P$ contains all but one of the literals in $\neg \mathcal{C}$.
\end{defs}

\begin{defs}
Given a partial assignment $P$, a literal $l$ is called a \textbf{unit literal} iff $l$ is in a unit clause $\mathcal{C}$, and $\neg l \not \in P$.  
\end{defs}

For example, a clause $\{a,b,c\}$ is unit if the partial assignment contains $\neg b$ and $\neg c$ but neither $a$ or $\neg a$.
The literal $a$ is then a unit literal.

For a formula to be satisfiable given partial assignment, each unit literal must be included in the partial assignment,
because if their negation is included the clause is not satisfied by the partial assignment.
For example, given a formula $\{c\}$, where $\mathcal{C} = \{a,b\}$;
given the assignment $\{\neg a\}$ the clause $\mathcal{C}$ is unit and unit literal is $b$.
If $\neg b$ where in the partial assignment, $\mathcal{C}$ would not be satisfied by the partial assignment,
therefore $b$ must be in the partial assignment for it to be a partial solution.

The process of unit propagation is defined in figure \ref{impl.propagation}.
\begin{figure}[htp]
\begin{center}
\begin{alltt}
unit-propagate(\(F, P\)):
  while P is consistent and there exists a \(\mathcal{C} \in F\) that given \(P\) is unit:
    \(l\) = unit literal in \(\mathcal{C}\)
    \(P\) = \(P \cup \{l\}\)
\end{alltt}
  \caption{Pseudo code of Unit Propagation}
  \label{impl.propagation}
\end{center}
\end{figure}

\subsubsection{Decide}
\label{impl.litorder}
The function \verb+decide+ returns a literal that is not in the partial assignment, nor whose negation is in the partial assignment.
That is, if $l =$ \verb+decide+$(P)$, then $\{l\} \not \in P$ and $\{\neg l\} \not \in P$.
This literal is then added to the partial assignment as an assumption that it might be in the final solution.
This assumption is checked to be correct or not by recursively calling the \texttt{DPLL} function again with the new partial assignment.

The order in which the \verb+decide+ function selects literals is also known as the literal order.
This order greatly impact the efficiency of the algorithm, as clearly selecting literals that are in a solution (if one exists) is the goal.

\subsection{Advancements in SAT Solvers}
Though the DPLL algorithm is the basis of most modern SAT solvers, the actual implementations have been significantly altered to increase efficiency.
Some changes, including the use of conflict learning, backjumping, and watched literals, are briefly described here.
This section should give a broad overview of the techniques used in current SAT solvers, 
in order to show that their application to problems like component evolution is justified. 

\subsubsection{Conflict Learning and Backjumping}
Conflict learning \citep{stallman1976} is a technique to cache previously tried sets of assignments in order to stop re-solving the same sub-problems.
This is accomplished by remembering what unit clauses, also known as reasons, caused literals to be added to the partial assignment through unit-propagation. 
This process works by identifying a variable both inferred to be true and false,
then creating a new clause, known as the learnt clause, which stops that inconsistency being reached again.
This learnt clause is derived by disjoining the two reason clauses after removing both the references to the inconsistent variable.
This process is shown in figure \ref{impl.clauselearning}. 

\begin{figure}[htp]
\begin{center}
$\begin{array}{c}
\{a_1,\ldots,a_k, l\} \\
 \{b_1,\ldots,b_m,\neg l\}\\
\hline
\{a_1,\ldots,a_k, b_1,\ldots,b_m \}
\end{array}$
  \caption{Clause Learning. Where $\{a_1,\ldots,a_k, l\}$ is the reason for $l$, and $\{b_1,\ldots,b_m,\neg l\}$ is the reason for $\neg l$
   are used to create the learnt clause $\{a_1,\ldots,a_k, b_1,\ldots,b_m \}$.}
  \label{impl.clauselearning}
\end{center}
\end{figure}

For example, if the reason for the inferred literal $a$ is clause $\{a, b\}$, and the reason for $\neg a$ is clause $\{\neg a, c\}$,
then the learnt clause derived is $\{b,c\}$, and added to the formula.

Backjumping \citep{Gaschnig1979} is the technique which determines how far to up the search tree to backtrack when a conflict is found.
The higher up the tree the technique ``jumps'' to, the greater reduction of the search space.
The level at which the algorithm backjumps is typically the point at which the learnt clause becomes unit. 

More advanced methods of conflict learning occur by minimising the size of the learnt clauses, as presented in \citep{sorensson2009}.
This research describes search methods that use other reason clauses to find smaller more succinct learnt clauses.
The smaller the clause, the more of the search tree is pruned and the more levels are backjumped through the search.

\subsubsection{Watched Literals}
As noted by studies into the efficiency of DPLL-based SAT solvers \citep{dixon2004automating}, unit propagation is where the bulk of the computation in DPLL occurs.
Attempts to increase the efficiency of this task was initially to find better heuristics \citep{JamesMCrawford1996} for the literal order, to encourage cascades of unit propagation.
These attempts were shown to work well on random SAT problems but be less efficient for large structured problems \citep{dixon2004automating}.

It was noted that within unit propagation most of the time was spent on identifying the unit clauses.
The naive approach to unit propagation was to examine every clause, and then every literal in the clause to find if it is unit or not.
A more efficient approach was proposed using watched literals \citep{Madigan2001}, where instead of having the clauses examined, 
the clauses maintain an index of the necessary literals and notify the algorithm when they become unit.
This ``don't call us, we will call you'' concept makes the efficiency of the unit propagation function less dependent on the amount of clauses in the formula.

Advances on watched literals have occurred through algorithms to maintain the index of literals, like that presented in \citep{Moskewicz2001}.
Such algorithms enable larger formulae to be solved without necessarily increasing the time to solve them.

\subsection{Iterative Strengthening}
The iterative strengthening algorithm, presented in \citep{calistri1994iterative} and \citep{le2010sat4j}, 
describes an anytime algorithm using constraint satisfaction that iteratively finds better solutions.
This algorithm can be used to find optimal solutions to an evolution problem, where only one pseudo-Boolean criterion is optimised.
This is done by first finding a solution, then iteratively adding constraints created from the criterion to ensure the next solution found will be better than the previous.
This is the strengthening process.
Strengthening continues until either the strengthened formula is found to be unsatisfiable, or the algorithm is interrupted, at which point the best solution currently found is returned. 
This algorithm is defined in figure \ref{impl.strength}.

\begin{figure}[htp]
\begin{center}
\begin{alltt}
iterative-strengthening(\(F\),\(\langle f\sb{\alpha}, R, I \rangle\)):
    \(F\) = \(F \cup I\)
    \(answer\) = DPLL(\(F\))
    if \(answer\) = UNSATISIFABLE:
        return UNSATISIFABLE
    do:
        \(model\) = \(answer\)
        \(J\) = strengthen(\(model\),\(\langle f\sb{\alpha}, R, I \rangle\))
        \(F\) = \(F \cup J\)
        \(answer\) = DPLL(\(F\))
    while not (interrupted() or  \(answer\) == UNSATISIFABLE)
    return \(model\) 
\end{alltt}
  \caption{Pseudo code of Iterative Strengthening Algorithm}
  \label{impl.strength}
\end{center}
\end{figure}

The first action in the \texttt{iterative-strengthening} is to initialise any auxiliary variables used by the criterion's pseudo-Boolean function.
This is accomplished by adding the criterion's initial constraints $I$ to the formula $F$.

The next action is to check if the formula is satisfiable.
This is accomplished by passing the formula to the \verb+DPLL+ function, and assigning its output to the variable $answer$.
If the output from \texttt{DPLL} is \texttt{UNSATISIFABLE}, then the algorithm stops and returns \texttt{UNSATISIFABLE}, as there are no solutions.

The main loop of this algorithm is then defined.
The first action in this loop is to assign the contents of the variable $answer$ to the variable $model$.
The variable $model$ is a set of literals, used as a store of the currently best found solution.

The function \texttt{strengthen} is then called to create a formula $J$.
The formula $J$ ensures that if \texttt{DPLL} is called with formula $F \cup J$, either:
\begin{itemize}
  \item a solution is returned that is better (w.r.t. the criterion) than the currently best found solution $model$. 
  \item \texttt{UNSATISIFABLE} is returned, showing that no better solution exists.
\end{itemize}

\begin{defs}
Given a set of literals $model$, and a criterion $\langle f_{\alpha}, R, I \rangle$,
the function \texttt{strengthen} returns a formula consisting of a single pseudo-Boolean constraint, $\{ \langle f_{\alpha},R,f_{\alpha}(model) \rangle \}$.
\end{defs}
That is, \texttt{strengthen} returns a formula $J$,
that ensures any solution $P$, to the formula $F \cup J$, must have a better ( w.r.t. $R$) value of $f_{\alpha}(P)$ than the previously best solutions value of $f_{\alpha}(model)$.

The next steps are then to add the formula $J$ to $F$, then search for a new solution using \texttt{DPLL}.

The main loop will end given the condition that either the \texttt{interrupted} function returns $true$, or the \texttt{DPLL} function returns \texttt{UNSATISIFABLE}.
The \texttt{interrupted} method is typically defined to return false until some external input (like a user stopping the algorithm or a timer running out) is encountered.
The \texttt{interrupted} method has the additional responsibility of stopping the \texttt{DPLL} function.
That is, if at any point \texttt{interrupted} returns true the \texttt{DPLL} function immediately returns $\emptyset$.
When the main loop ends, currently best found solution $model$ is returned.

\subsection{Lexicographic Optimisation}
\label{impl.lexiterstre}
%%%Basic iterative strengthing can be modified towards handling lexicographically ordered crtiera, and allowing this criteria to effect DPLL's efficiency
The basic iterative strengthening algorithm, presented in figure \ref{impl.strength}, can be used find optimal solutions to lexicographically composed criteria.
This can be accomplished by iteratively strengthening the each composed criteria in order of lexicographical composition.
This lexicographic iterative strengthening algorithm is presented in figure \ref{impl.lexstrength}.

\begin{figure}[htp]
\begin{center}
\begin{alltt}
lexicographic-iterative-strengthening(\(F\),\(\langle{}\mathfrak{crit}\sb{1}, \ldots ,\mathfrak{crit}\sb{n}\rangle\)):  
    \(answer\) = DPLL(\(F\))
    if \(answer\) = UNSATISIFABLE:
        return UNSATISIFABLE
    \(i\) = 0
    \(model\) = \(answer\)
    do:
        \(i = i + 1\)
        \(K\) = lock(\(model\),\(\mathfrak{crit}\sb{i}\))
        \(F\) = \(F \cup K\)
        \(model\) = iterative-strengthening(\(F\),\(\mathfrak{crit}\sb{i}\))
    while not (interrupted() or \(i\) == \(n\))
    return \(model\) 
\end{alltt}
  \caption{Pseudo code of the Lexicographic Iterative Strengthening Algorithm}
  \label{impl.lexstrength}
\end{center}
\end{figure}

The first action of the \texttt{lexicographic-iterative-strengthening} algorithm is to check if the formula is satisfiable using the \texttt{DPLL} algorithm.
If it is unsatisfiable, this algorithm returns \texttt{UNSATISIFABLE}.

The variable $i$ is then defined, this variable is a counter used to select the criterion to be strengthened.
Also, $model$ is assigned to be the set of literals $answer$, and is used to store the currently best found solution.

The main loop of this algorithm is then defined.
This loop first increments the counter $i$, to select the appropriate criterion to be strengthened.

The function \texttt{lock} is then called to return a formula $K$.
The formula $K$ ensures that if \texttt{DPLL} is called with $F \cup K$:
\begin{itemize}
  \item a solution is returned that is not worse (w.r.t. the criterion $\mathfrak{crit}_i$) than the solution $model$. 
\end{itemize}

\begin{defs}
Given a set of literals $model$, and a criterion $\langle f_{\alpha}, R, I \rangle$,
the function \texttt{lock} returns a formula consisting of a single pseudo-Boolean constraint, $\{ \langle f_{\alpha},R',f_{\alpha}(model) \rangle \}$,
where if $R = <$ then $R' = \leq$, else if $R = >$ then $R' = \geq$.
\end{defs}
That is, \texttt{lock} returns a formula $K$,
that ensures any solution $P$, to the formula $F \cup K$, must not have a worse ( w.r.t. $R$) value of $f_{\alpha}(P)$ than the value $f_{\alpha}(model)$.

It is important to note that $K$ does not effect the satisfiability of $F$, as $model$ is still a valid solution to $F \cup K$.

The formula $K$ is then added to the formula $F$, i.e. $F = F \cup K$,
then the \texttt{iterative-strengthening} algorithm is called to find an optimal solution to $F$ given the criterion $\mathfrak{crit}_i$.
As the formula $F$ is known at this point in the algorithm to be satisfiable, the only possible returned value from \texttt{iterative-strengthening}
is a solution that is no worse than $model$.
This means that the returned value could be equivalent to the previously defined solution, if there exists no better solution than what has already been found.

The main loop will iterate until either all the criteria have been optimised, or the function is interrupted.
When the loop ends, the currently best found solution $model$ will be returned.

Some enhancements to the implementation of the lexicographic iterative strengthening algorithm can be made.
For example, when the \texttt{iterative-strengthening} is called, it is known that $F$ is satisfiable. 
Therefore, checking its satisfiability again within the \texttt{iterative-strengthening} function is not necessary.
Such enhancements were made in GJSolver, to increase the efficiency of this algorithm. 

\subsection{Drawbacks of this Optimisation approach}
%%%There are a few drawbacks to this mapping;
There are some drawbacks to using the lexicographic iterative strengthening algorithm (as described earlier) 
as GJSolver's method of optimisation.

%%%The optimisation must be represented linearly
GJSolver uses the SAT4J solver as its implementation of the DPLL function. 
It has been noted in \citep{le_berre_dependency_2009} and \citep{leBerre2010} there is no easy method of extending a SAT solver to handle non-linear constraints.
This means that many criteria that could be defined in the formalism, presented in chapter \ref{formal}, will either not be able to be represented as pseudo-Boolean criteria, 
or they will be inefficient to use a SAT solver to find optimal solutions.  
The trade-off for not including the ability to define more complex criteria is that GJSolver is relatively simple and efficient. 

%%%Real numbers must be truncated to fit the integer representation. 
The pseudo-Boolean criteria can only be defined to use integers and not real numbers.
This means that defining criteria that optimise real values, like percentages, a challenge.
The practical solution used by GJSolver is to scale real numbers up, and truncate them to be an integer.
Scaling these values may remove a small amount of resolution of the real value.
Though this can be mitigated by allowing criteria to define their own scale value.

\section{GJSolver}
\label{impl.gjsolver}
Using the algorithms and mappings that have been presented,
the GJSolver is implemented to complete one evolutionary step of a component system.

GJSolver takes as input (as described in \ref{impl.MISCDEF}):
\begin{itemize}
  \item \verb+cudfin+: a relative path to a CUDF document.
  \item \verb+cudfout+: a relative path to a non-existent file.
  \item \verb+criteria+: is a string in MOF. 
\end{itemize}

As described in chapter \ref{formal}, these values are then mapped to the formal model:
\begin{itemize}
  \item the CUDF file at \verb+cudfin+ is mapped to an evolution problem ($\delta_{t_i} \cup \omega_{t_i}$) and a component system ($\alpha_{t_{i-1}}$).
  \item the MOF description \verb+criteria+ is mapped to a lexicographically ordered set of criteria ($crit_1 \oplus \ldots \oplus crit_n$), each w.r.t. $\alpha_{t_{i-1}}$.
\end{itemize}

As described in section \ref{impl.mapping}, these values are mapped to a SAT problem and pseudo-Boolean criteria:
\begin{itemize}
  \item the evolution problem $\delta_{t_i} \cup \omega_{t_i}$ is mapped to a SAT formula ($F$).
  \item the criteria $crit_1 \oplus \ldots \oplus crit_n$ are mapped to a tuple of pseudo-Boolean criteria ($\langle \mathfrak{crit}_1, \ldots ,\mathfrak{crit}_n \rangle$), each w.r.t. $\alpha_{t_{i-1}}$. 
\end{itemize}

Using the \texttt{lexicographic-iterative-strengthening} algorithm (described in section \ref{impl.lexiterstre}),
with the input $F$ and $\langle \mathfrak{crit}_1, \ldots ,\mathfrak{crit}_n \rangle$, an optimal solution is searched for.
This search is interrupted after five minutes has elapsed, this timeout value is used in the MISC competition.
If the algorithm returns a solution as a set of literals, that solution is mapped to component system $\alpha_{t_i}$.
If the algorithm returns \texttt{UNSATISIFABLE}, no solution to the evolution problem exists, and $\alpha_{t_i} = \alpha_{t_{i-1}}$ 
(as defined in the evolutionary step definition \ref{formal.stepdef}).

The component system $\alpha_{t_i}$ is then converted into CUDF, which is then written to a file at the location \verb+cudfout+.

\section{GJSolver}
\label{impl.gjsolver}
Through the course of this research, the CDR implementation GJSolver grew out of the need to have a modifiable base to experiment with component dependency resolution.

Given the context under which GJSolver was developed, the set of requirements that it was designed according to are listed here:
\begin{enumerate}
  \item \textbf{Mancoosi International Competition Ready}: The MISC gives a set of standards to solve CUDF problems with criteria defined using the Mancoosi optimisation format.
  A goal of the GJSolver was to enter it in the MISC in order to be compared against other solvers.
  This comparison would be the final step in the validation and verification of the implementation.
  Following these standards ensures that the solver can be entered, and then competing can show the relative speed and correctness of the GJSolver implementation.
  This will ensure that GJSolver is a valid and efficient implementation. 
  \item \textbf{Anytime Algorithm}: Return a solution, even if it is not an optimal solution, within a predefined amount of time. 
  CDR problems can be large and complex, finding the ``best'' solution can be difficult. 
  This requirement ensures that the algorithm will return a solution, within a time frame.
  \item \textbf{Easily Creatable Criteria}: The ability to quickly implement and test criteria in a manner that enables experimentation, will increase the speed of research.
\end{enumerate}

\subsection{Mancoosi International Solver Competition}
\label{impl.MISCDEF}
Given a goal of the GJSolver implementation is to compete in the MISC, the interface and standards defined for this competition must be followed.
How the entered solvers are executed, what environment they are executed in, and the output required are all important aspects to the development of GJSolver.

%%%They are executed on the command line
The way in which the entered solvers are executed is standardised to allow the automation of the competition.
This standard requires the entered solvers to be able to be executed on the command line with three arguments, \verb+cudfin+, \verb+cudfout+ and \verb+criteria+.
These arguments are defined as:
\begin{itemize}
  \item \verb+cudfin+: is a relative path to a CUDF document (as specified in section \ref{formal.cudf}) that describes the problem to be solver.
  \item \verb+cudfout+: is a relative path to a non-existent file, which is created by the solver to output the solution.
  \item \verb+criteria+: is a Mancoosi optimisation format (as described in section \ref{formal.mancoosioptimisationformat}) description of the criteria to select an optimal solution. 
\end{itemize}
The format of the output file, located at the path defined with \verb+cudfout+ argument, is a sub set of CUDF.
This output only requires package stanzas with the package name, version and installed properties.
This lowers the size of the output file required to be written by the solver.

%%%The environment POSIX, with 5minutes 1GB of memory
The environment in which the solver is executed is a virtual machine running a GNU/Linux system in a x86 architecture with 1GB of RAM.
It contains a Java runtime environment, allowing the use of Java as a primary language.
The time in which the solver is allowed to run is five minutes, after this time the solver will be forcibly executed.
This time limit ensures that the competition can be run in an acceptable time frame.

\subsection{Anytime Algorithm}
The time required to find an optimal solution to a component evolution problem can be longer than the allowed time within the MISC environment.
For this reason, GJSolver will be implemented with an anytime algorithm at its core.
An anytime algorithm can return a valid solution to a problem if it is interrupted before it ends.
This interruption could be from a user or some other stimuli.
In the case of GJSolver, the interruption will be caused by an internal timer dedicated to ensure that the algorithm does not run in time exceeding the 5 minute deadline.

Such anytime algorithms therefore create a trade-off between time and optimality, where the more time that is set aside for the algorithm to run the more optimal the solution. 
They can also create inconsistent results, as any input may, on different runs, return many different possible solutions.
This means that if it is necessary to interrupt the algorithm, it is possible to return non-optimal solutions.
However, this is only if interruption is necessary, as GJSolver will encounter a wide range of difficult problems, 
it is difficult, or impossible, to judge beforehand if a problem will require the algorithm to be interrupted. 

\subsection{Expendable Criteria}
The ability to test and experiment with a wide range of possible criteria to use in CDR is a goal of this research.
To satisfy this requirement, GJSolver was developed in a modular manner, in which the criteria can be extended, modified, and tested when solving problems quickly.

\subsection{Design}
%%%TODO this section
The first decision made about the design of GJSolver was to base it on another CDR implementation, Eclipse P2 \citep{le_berre_dependency_2009,leBerre2010}.
Basing the design on an existing implementation allowed the reuse of tools, and most importantly the reduction in risk that the implementation will not satisfy the requirements.
Eclipse P2 satisfies two of the three requirements: being MISC ready as it has a MISC implementation, and using an anytime algorithm to find solutions. 

The basis of GJSolver on Eclipse P2 lead to the following choices:
\begin{itemize}
  \item Java as the main implementation language
  \item SAT4J as the core SAT and PB solver
  \item Represents criteria as pseudo-Boolean function
  \item Finds an optimal solution through iterative strengthening
\end{itemize}

The main aspects where GJSolver does not reuse, or replicate Eclipse P2 is because P2 is designed especially for the OSGi and Eclipse component model, where GJSolver is designed for CUDF.
Som of the differences between Eclipse P2 and GJ Solver are:
\begin{itemize}
  \item No OSGi or Eclipse specific code in GJSolver
  \item The internal representation of components is based on CUDF and not on OSGi
  \item Not representing all criteria as a single pseudo-Boolean function
\end{itemize}

By starting with Eclipse P2 as a model, GJSolver was able to be efficiently implemented.

\subsection{SAT4J}
Given the use of SAT4J in GJSolver, a brief background of its development is presented here.

MiniSAT presented in \citep{een2003}, is a simple SAT solver implementation written in C, and designed for speed and extensibility.
It uses the DPLL based conflict driven algorithm as discussed above.
This solver has become popular and is the basis of many other SAT solvers due to its open source distribution.
This has also lead to a track in the 2011 SAT competitions\footnote{http://www.satcompetition.org/2011/ accessed 6/3/2012} that deals with only altering MiniSAT to increase performance.
This means that MiniSAT has been repeatedly validated for performance by third parties across many difference SAT problems. 

SAT4J \citep{le2010sat4j} is a Java re-implementation, and extension, of MiniSAT in the Java programming language.
The extensions SAT4J makes to MniSAT include the ability to find resolve pseudo-Boolean constraints.
SAT4J was developed in order to quickly test combinations of advancements in SAT solving technology.
This goal has created an easily modifiable and transparent implementation, able to be adapted to be used in various domains.
SAT4J in this right has been a success.

\subsection{Verification of GJSolver}
\label{impl.verif}
%%%We entered this solver into two Mancoosi MISC competitions
The GJSolver implementation was verified by entering it into the Mancoosi International Solver Competition, whose requirements are described above.
This process was taken twice, firstly in a MISC Live event, which is an interim competition held during the year;
secondly at the MISC 2011 event\footnote{The results for MISC 2011 were announced at the Workshop on Logics for Component Configuration\footnote{http://www.pps.jussieu.fr/~treinen/lococo/2011/ accessed 6/3/2012}.}, 
which is the main competition. 

The main difference to GJSolver as described above, and the GJSolver entered into the MISC competition occurs when the evolution problem is unsatisfiable.
In the evolutionary step definition (\ref{formal.stepdef}) the component system $\alpha_{t_{i-1}}$ is returned if the evolution problem is unsatisfiable.
However, in this case, MISC requires that a file with only the text \texttt{FAIL} is written to the location of the output CUDF file.
This is to correctly score a solver returning an incorrect solution to an evolution problem, 
and a solver finding an unsatisfiable problem.

\subsubsection{Tracks and Scoring}
Each MISC competition is broken down into three possible tracks, where each track is defined by the criteria used.
The first basic track, is 'paranoid', the second more advanced track is 'trendy', and third track is 'user'.
Both 'paranoid' and 'trendy' have pre-defined criteria defined in MOF.
The 'user' track uses a set of pre-defined criteria, though does not express their relation in MOF, so the exact optimisation criteria is unknown before the competition.
This means that 'paranoid' and 'trendy' can have solvers tailored to their specific criteria, where the 'user' track cannot.
The exact criteria that is used in these tracks are defined in the next chapter.

For each track, a set of solvers is entered.
Each track has a set of evolution problems defined in CUDF.
The solvers for each track are then called to return optimal solutions for all problems given the tracks criteria.
As MISC competitions were created to compare various solvers, a scoring system was developed. 

When a solver is given a CUDF problem and some criteria, the returned solution falls into one of three classes:
\begin{itemize}
  \item a \textbf{real solution} is any solution to the CUDF problem.
  \item \textbf{no solution} occurs when a solver finished without returning a solution. This can happen because of error, timeout, or there not being a satisfiable solution.
  \item an \textbf{incorrect solution} occurs when the solver returns an answer that is not a solution to the CUDF problem.
\end{itemize}

Given $m$ is the number of solvers that entered into the track, the scoring of a solvers solution to an individual CUDF problem is as follows:
\begin{itemize}
  \item a \textbf{real solution} is given $1$ point, with an additional $1$ point for every solver that found a better solution.
  \item for \textbf{no solution} $2\times m$ points are given
  \item for an \textbf{incorrect solution} $3 \times m$ points are given.
\end{itemize}
This means, if a solver returns an optimal solution to a CUDF problem, it will receive $1$ point.
However, if other better solutions are returned, then the solver could be given up to $m$ points.

For each track, all solvers in that track are assigned points based on their solutions to all problems in that track.
For a given track a solvers points are summed to give a final score.
If more than one solver has the same amount of points at the end of a track, then the time it took for them to find each solution is summed.
This total time value is used as the tie breaker.

\subsubsection{MISC Live}
%%%In the first competition we had only partially implemented much of the functionality, so we did not expect great results.
The MISC Live was entered without GJSolver being fully implemented.
Therefore, the only track that was possible to enter was the 'paranoid' track.
The results for this track\footnote{http://mancoosi.org/misc-live/20101126/paranoid/ accessed 6/3/2012} where promising, though some improvements were necessary.
Due to the competition openly distributing all problems in each track, all the solutions of all solvers for all tracks, 
and the output from each solver;
GJSolver's deficiencies were easily identified and corrected.

\subsubsection{MISC}
The main verification of GJSolver was through the MISC 2011 event.
In this event GJSolver was entered into all tracks of this event.
The 'paranoid' track had a total of 5 solvers, the 'trendy' track had a total of 6 solvers, 
and the 'user' track had a total of 4 solvers.
Each track was also entered by the solver which GJSolver is based on, Eclipse P2, and another efficient solver aspuncud.
These two solvers will form the basis of GJSolver's comparison.

The scores and the times for each of the track compared to that from Eclipse P2 and aspuncud are in table \ref{impl.misc2011}.
\begin{table}
\begin{tabular}{| l | c | c | c | c |}\hline
Track & \# of Problems & GJSolver & P2 & aspuncud\\ \hline
paranoid & 129 & (190 : 5,294) & (181 : 4,646) & (147 : 1,035) \\ \hline
trendy & 129 & (197 : 13,073) & (232 : 13,435) & (151 : 1,767) \\ \hline
user & 400 & (656 : 73,522) & (1392 : 87,956) & (1215 : 39,905) \\ \hline
\end{tabular}
\caption{Results from MISC 2011, results are (score:time in seconds)}
\label{impl.misc2011}
\end{table}

The winner for both 'paranoid' and 'trendy' tracks was the aspuncud solver.
The winner for the 'user' track was GJSolver.

\subsubsection{Analysis}
The results from the MISC competition can be compared to the previously stated requirements.
The requirements for GJSolver are to be \textbf{Mancoosi International Competition Ready}, should implement an \textbf{Anytime Algorithm} and should be \textbf{Easily Creatable Criteria}.

\begin{itemize}
  \item The results from MISC show that GJSolver was ready for its entrance, during the competition it had very consistent results.
These results allowed it to compete with the other solvers, and even win the 'user' track.
\item The implementation of the anytime algorithm was shown through the many hard problems required to be solved.
This can be seen in many of the problems in the 'trendy' track, these required a lengthy search and many required interruption of the algorithm to return the currently best found solution.
Looking at many of these timed out problems, reveals that many of them returned optimal solutions regardless of the fact they were stopped before finishing the search.
This leads to the presumption that the finding of the optimal solution is not necessarily the time consuming part of the search, but the proof that there are no better solution remaining.
\item The criteria that were defined in to enter this competition were wide ranging, and will be specifically discussed in chapter \ref{strategies}.
It may be said that the reason for GJSolvers win of the 'user' track could be put down to the easily defined and tuning criteria that allowed the quick testing of different heuristics.
\end{itemize}

\section{Summary}
In this chapter, the implementation and validation of GJSolver is described.
First an evolution problem was mapped to a SAT problem, and the criteria where mapped to pseudo-Boolean criteria.
The algorithms used to find an optimal solution to the SAT problem given lexicographically ordered pseudo-Boolean criteria, was described.
These algorithms include, DPLL, iterative strengthening, and lexicographic iterative strengthening.
The validation of GJSolver, through the MISC competitions was discussed, and analysed.
This validation shows that GJSolver satisfies the original requirements of its design, and is capable of being used within this research. 
