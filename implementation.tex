\chapter{Implementation}
\label{implementation}
\epigraph{What I cannot create, I do not understand.}
{\textit{Richard Feynman, 1988}}

%%%CDR Has been shown to be NP-Complete to find a solution and NP-Hard to find an optimial one.
As presented in the previous chapter, the problem of evolving a component system was shown to be NP-Complete, and the problem of finding an optimal evolution was shown to be NP-Hard.
Therefore, to automate this complex evolution process it will require an efficient algorithm and implementation to not only find satisfiable solutions, but also optimal ones. 

%%%The efficiency of the implementation is important as the problem can combinatorially grow into a hard problem 
The efficiency of the implementations is necessary for many instances of CDR problems.
The goal of many component models is to have large amounts of components with support creating multiple versions of each component.
This directly makes the complexity of evolution grow in a combinatorial manner, making any ad-hoc or overly simple CDR implementation quickly overwhelmed.
The CDR algorithm should then be implemented to be robust and fast.

%%%Formally it resembles the SAT problem, which already has efficient implementations, and has been used to solve this problem
The formal representation of this problem was presented as a set of constraints that must all be satisfied in order for a component relationships and the user request to be fulfilled.
This structure closely resembles the Boolean Satisfiability Problem (SAT), which has fast, robust solver implementations that can be used.
This has been noticed by other researchers \citep{leberre2008,Mancinelli2006} 
and the use of SAT solvers to implement CDR in both academia \citep{abate2011} and industry \citep{leBerre2010} has become common.

%%%Finding the optimial solutions requires extensions to SAT solvers
The finding of an optimal solution though is difficult when using a ``pure'' SAT solver, as it cannot easily represent constraints relating to criteria. 
However, through extending the SAT solver implementations to also handle other types of constraints, such as pseudo Boolean constraints, optimisation becomes significantly easier.

%%%In this chapter\ldots
In this chapter the algorithms and implementation of CDR using SAT solvers extended with pseudo Boolean constraints, are discussed.
First the Davis-Putnam-Logemann-Loveland algorithm \citep{Davis1960, davis1962machine} and its extensions, which are the basis for many current SAT solvers, are described.
This will give a basic understanding of the internal workings of current SAT solvers.
The specific implementation of Eclipse P2 and P2CUDF by \cite{leBerre2010} is then described,
this is given as a comparison of a current technology used by CDR implementations.
Then the description of this research's CDR implementation, GJSolver, is given.
The specific reason for the necessary changes, the differences from other solutions, and the advantages to using it.
This also describes the process in which it was validated and compared against other solvers in the MISC 2011 competition.

\section{Boolean Satisfiability Solvers}
\label{impl.SAT}
Boolean satisfiability (SAT) is the problem of determining if the variables in a Boolean equation can be assigned in such a way that the equation returns true.
This problem was the first identified NP-Complete problem, meaning that no known algorithm exists that efficiently solves all instances of SAT problems.
This also means that many proofs of NP-Completeness is through the reduction to SAT, and therefore many difficult problems have been expressed in the terms of a Boolean equation.
The benefit of this is that algorithms and implementations of programs that solve SAT problems have received significant attention and research to provide solutions to these various problems.
Taking advantage of these algorithms will help with the creation of a CDR implementation that can robustly evolve a component system.

%%%SAT solvers are used to solve many problems, creating a community dedicated to creating fast implenmenations
SAT solvers have been used in various domains to tackle problems such as electronic design automation \citep{Marques-Silva2000}, 
model verification \citep{dennis2006}, and, of course, component system evolution \citep{leBerre2010}.
These uses have caused a great need to create efficient solvers, and this has spawned a community dedicated to creating efficient implementation.
This community, creates and improves their solvers, 
and as a means of validating their creations, regularly compare them against one another in a series of competitions \footnote{http://www.satcompetition.org/}.
Using a competition for progress not only encourages the improvement of solvers for a particular problem set, but also general improvements to the algorithms and heuristics used. 

%%%In this section a common implementation of SAT solvers is discussed, the DPLL algorithm
In this section, first a brief definition of the SAT problem is described, this defines much of the terminology in this domain used in the description of algorithms and implementations. 
Then a short description of the DPLL algorithm is given, this algorithm is the basis of most current SAT solvers and therefore is required knowledge to discuss current implementations.
A common variant of the DPLL algorithm in current SAT algorithms is the alteration to become conflict driven,
this alteration is presented and discussed.
The extension of this algorithm with Pseudo-Boolean constraints is then described,
as this extension allows for more complicated optimisation problems to be represented.
Finally, other methods of solving SAT problems are briefly discussed to give a broader description of the domain. 

\subsection{The SAT Problem}
As described above, the goal of a SAT algorithm is to find whether a set of variables in a Boolean equation can be assigned values in such a way as to make the equation equal true.
The way in which such equations can be described is varied, though a common standard to use is the Conjunctive Normal Form (CNF).
CNF describe a conjunction of clauses, where each clause is a disjunction of literals, e.g. $(a \vee b) \wedge (\neg b \vee c)$.

Before we further describe the problem some of the language from this domain will be further defined here:
\begin{itemize}
  \item $V$ is a set of variables
  \item The atomic formula of a variable or its negation is defined as a literal; each variable $v$ in $V$ maps to two literals, either $v$ or $\neg v$.
  \item A clause is a set of literals, e.g. $\{\neg b, c\}$ which in CNF represents the equation $\neg b \vee c$
  \item A CNF formula $F$ is a set of clauses, where each clause is a set of literals, e.g. $\{\{a, b\} , \{\neg b, c\} \}$ which in CNF represents the equation $(a \vee b) \wedge (\neg b \vee c)$.
\end{itemize}

Through this representation some of the terms used to define the algorithms are defined as:
\begin{itemize}
  \item A unit clauses is a clause with only one literal, i.e. a clause $c$ is unit iff $|c| = 1$.
  \item A unit literal is the literal in a unit clause, e.g. a unit clause $\{l\}$ has the unit literal $l$.
  \item A set of literals $L$ is said to be inconsistent if for any variable $v$, both literals $v$ and $\neg v$ are in $L$,
  \item A set of literals $L$ is said to be consistent if it is not inconsistent
  \item A set of clauses is said to be consistent (or inconsistent) if the set of its unit literals are consistent (or inconsistent)
\end{itemize}

Finally, the definition of the satisfiability of this CNF representation is given:
\begin{itemize}
  \item A clause $c$ is said to be satisfied given a set of literals $L$, if $|L| = |V|$, $L$ is consistent, and if there exists a literal $l$ in $c$, such that $l \in L$.
  \item A formula $F$ is said to be satisfied given a set of literals $L$, if $|L| = |V|$, $L$ is consistent, and all constraints in $F$ are satisfied by $L$.
  \item A formula $F$ is said to be satisfiable if there exists a set of literals $L$ where the $F$ is satisfied by $L$.
\end{itemize}

This representation of the SAT problem using CNF will be used in the following sections to define the algorithms used to solve it.

\subsection{Davis-Putnam-Logemann-Loveland algorithm for SAT Solvers}
%%%A successful algorithm for solving SAT problems is the DPLL algorithm, here we describe it in overview
The Davis-Putnam-Logemann-Loveland (DPLL) algorithm \citep{Davis1960, davis1962machine} for solving SAT problems is a complete (meaning it will find a solution if one exists), 
backtracking-based search algorithm for SAT problems represented in conjunctive normal form (CNF).

It runs by selecting a variable from the Boolean formula, and altering the formula with the assumption that variable is true, then calling itself to find if the new formula is satisfiable.
If it finds that the new formula is unsatisfiable, then it alters the formula by assuming that the variable is false, then searching again to see if the new formula is satisfiable.
Though the search the formula is simplified through the processes of unit-propagation and pure literal elimination.
When this reduction alters the formula to a state where it is trivial to identity whether it is either satisfiable or unsatisfiable, the algorithm returns the result.

The DPLL algorithm in defined in figure \ref{impl.DPLL}:

\begin{figure}[h]
\begin{center}
\begin{alltt}
function DPLL(\(F\))
   if \(F\) is a consistent set of unit clauses:
       then return true;
   if \(F\) contains an empty clause:
       then return false;
   for every unit literal \(l\) in \(F\):
      \(F\) = unit-propagate\((l, F)\);
   for every literal \(l\) that occurs pure in \(F\):
      \(F\) = pure-literal-assign\((l, F)\);
   \(l\) = decide\((F)\);
   return DPLL\((F \cup \{l\})\) or DPLL\((F \cup \{\neg l\})\);
  		
\end{alltt}
  \caption{Recursive DPLL algorithm}
  \label{impl.DPLL}
\end{center}
\end{figure}

The first \verb+if+ branch of the DPLL algorithm finds if the formula is satisfiable only if it consists of consistent unit clauses.
The second \verb+if+ branch determines if the formula is unsatisfiable by looking for a clause that contains no literals, thus it is unsatisfied.

The first loop of the algorithm aims to remove literals from clauses in $F$ whose negation are in unit clauses.
For example, if $F = \{c1,c2,c3\}$ where $c1 = \{v\}$ $c2 = \{\neg v, a\}$ and $c3 = \{\neg a , x\}$,
the set of unit clauses in $F$ is $\{c1\}$ making $v$ the only unit literal.
Therefore, \verb+unit-propagate+$(v,F)$ removes all $\neg v$ literals, making $c2 = \{a\}$.
This propagation then made the clause $c2$ and literal $a$ unit, continuing the process with \verb+unit-propagate+$(a,F)$ which makes $c3 = \{x\}$, making $x$ unit.
So this process of unit propagation turned $F$ into a set of unit clauses, making it satisfiable.

The second loop simplifies the formula by removing the clauses which are known to be true, as they are superfluous to the formula.
This is done by identifying literals which have no negation in the formula (known as pure literals), and then removing any clause which contains that literal.
For example, if the formula $F = \{c1,c2,c3\}$ where $c1 = \{v\}$ $c2 = \{\neg v, a\}$ and $c3 = \{\neg a , x\}$, 
the set of pure literals equals $\{x\}$ as it has no negation in any clause.
Therefore, \verb+pure-literal-assign+$(x,F)$ would remove the clause $c3$ from the formula, so $F = \{c1,c2\}$, this in turn makes $a$ pure.
Once \verb+pure-literal-assign+$(a,F)$ then eliminates $c2$ from the formula to leave $F= \{c1\}$ making all clauses unit in the formula thus it is satisfiable.

The function \verb+decide+ returns a literal that is not unit, nor whose negation is unit, i.e. given $l =$ \verb+decide+$(F)$, $\{l\} \not \in F$ and $\{\neg l\} \not \in F$.
This literal is then added to the formula and checked for satisfiability.
If the formula is not satisfiable, then the negation is added to the formula and checked for satisfiability.  
The order in which the variables from the formula are selected will have a great impact on the speed at which the algorithm finds the formula to be satisfiable or not.
This function will be described further in this chapter, as it clearly has a large impact on the DPLL algorithms use.


\subsection{Conflict driven Solvers}
Though the DPLL algorithm is the basis of most modern SAT solvers, the actual implementations have been altered to increase efficiency.
A common change is to alter it from being a recursive propagation based algorithm to a conflict driven, clause learning algorithm.
This modern variant, analyses the reasons for conflicts that occur during the search, and then creates new clauses in order to prune the search tree efficiently.
A conflict driven DPLL algorithm is described in figure \ref{impl.conflictSAT}.

\begin{figure}[htp]
\begin{center}
\begin{alltt}
conflictDrivenDPLL(F):
    trail = \(\{\}\)
    loop:
        clause = propagate(F,trail)
        if clause = null:
            if trail satisfies F:
                return true
            else:
                l = decide(trail)
                trail = trail \(\cup \{ \) l \(\}\)
        else:
            conflict = analyse(clause)
            F = F \(\cup\) conflict
            if F is inconsistent:
                return false
            else:
                backtrack(F,trail)
			
\end{alltt}
  \caption{Conflict Driven SAT solver algorithm}
  \label{impl.conflictSAT}
\end{center}
\end{figure}

This particular conflict driven DPLL algorithm is based on MiniSAT, presented by \cite{een2003}.
This implementation was built for efficiency and simplicity, and provides a basic description of the important aspects of such algorithms.

The initial instruction in this algorithm is to create a set of literals, called the \verb+trail+, that store the set of assignments that are made during the loop.
This trail is typically implemented as a stack for efficiency reasons, though here for simplicity it is represented as a set.
It contains the literals, which have either been inferred through propagation, or assumed through the \verb+decide+ method. 
The goal of this algorithm is to find a set of literals to populate trail, where $F$ is satisfied by them.

The functions of \verb+propagate+, and \verb+decide+ have been altered slightly from the original DPLL algorithm, though are still in essence the same.
The additional functions of \verb+analyse+ and \verb+backtrack+ give this algorithm a more efficient means of searching for a formula's satisfiability.

\subsubsection{Propagation}
%%%Propagate
The propagation function in the base DPLL algorithm uses unit clauses in the formula to eliminate literals in the various clauses.
In this conflict driven approach, the \verb+propagate+ function uses the formula clauses and the trail, to infer more literals to be added to the trail.
If the inferred literals create a trail where a clause becomes inconsistent, the clause is returned as a flag that a conflict has been found.
The \verb+propagration+ function is described in figure \ref{impl.conflictpropogate}.

\begin{figure}[htp]
\begin{center}
\begin{alltt}
propagate(F,trail):
    continue = true
    while continue:
        continue = false
        for clause in F:
            lits = clause - trail
            if |lits| = 0: #clause is inconsistent
                return clause
            if |lits| = 1: #clause is unit
                trail = trail \(\cup\) lits
                if trail is inconsistent:
                    return clause
                continue = true
\end{alltt}
  \caption{Conflict Driven SAT solver algorithm}
  \label{impl.conflictpropogate}
\end{center}
\end{figure}

This algorithm iterates until no more literals can be inferred into the trail, through using the flag \verb+continue+.
The inner loop iterates over all the clauses in the formula looking for either an inconsistency created by the trail, or a clause which becomes unit because of the trail.
If either a clause or the trail becomes inconsistent then the offending clause is returned to be used in conflict analysis.

\subsubsection{Literal Order}
%%%Decide
Like in the original DPLL algorithm, the decide function greatly effects the efficiency of this algorithm.
The main difference in this algorithm is the manner in which the variable is used to guide the search path.
In the DPLL algorithm, the deciding literal is first added to the formula, and if that results in an unsatisfiable formula, then it's negation is added.
In this conflict driven algorithm, the deciding literal is added to the trail, and the formula is left unaltered.

\subsubsection{Conflict Analysis and Backtracking}
The \verb+analyse+ function takes a clause and returns another clause that defines the reason for the conflict to of occurred.
For this method to work
This method of \cite{stallman1976}

%%%Conflict learning


\subsection{Pseudo-Boolean Optimisation of SAT Solvers}
%%%Optimisation of SAT solvers is typically done through extending their possible constraints to include Psuedo Boolean inequalities

%%%Then through repeatdly finding a solution then adding a constraint to ensure the next solution is at least as good, the best solution is found

%%%Further optimisation can be made through quickly finding a satisfactory solution, this reduces the space in which to find a better solution

\subsection{MiniSat and SAT4J}
MiniSAT presented in \cite{een2003}, is a simple SAT solver implementation written in C, and designed for speed and extensibility.
SAT4J is a Java implementation, and extension, of that is used in a variety of domains as it is fast and thoroughly verified.
Both of these solvers use similar conflict driven DPLL algorithms presetned earlier, and thus are complete, fast and efficient solvers of SAT problems.
This can be seen, as both solvers have regularly been entered into SAT solving competitions, where their results are excellent.

\subsection{Other Methods}
This \cite{Stuckenholz2007} study looks at using boolean optimisation with branch and bound as a solution, as does \cite{Jenson2010a}.


\subsubsection{Integer Programming}
%%%Discussion of this method as the best MISC solver uses this, it has a very complex implementation
\subsubsection{SMT Solvers}
%%%SMT Solver, a slightly higher logic than SAT uses; it has to broad a definition when SAT suffices
\subsubsection{Constraint Solver}
%%%We could just use Prolog, like SMT I think it is too broad when there are good SAT solvers


\section{GJSolver}
%%%My Implementation, cut the fat, straight forward
Through the course of this research an implementation grew out of the need to have a modifiable base to experiment with component dependency resolution.
Other implementations of CDR where often platform specific, or involved difficult (or impossible) to modify code.
This CDR implementation is know as GJSolver, and is directly designed to solve CDR problems represented in CUDF, with optimisation descriptions in Mancoosi format.

SAT4J was used as a base for the satisfiability, where minor non-critical code was altered in order to interface with it correctly.


\subsection{Product and Lexicographic orders in Pseudo-Boolean Optimisation}
%%%Here we descirbe the mapping from our Optimisation framework to PBO, product order is easy, lexicographic requires some muddling

\subsection{Drawbacks of this Optimisation approach}
%%%There are a few drawbacks to this mapping;
%%%These simplifications are mostly necessary for this problem as it keeps the problem manageable,
%%%and including all aspects of our formal optimisation framework would be practically impossible

%%%The optimisation must be represented linearly
As noted in \cite{le_berre_dependency_2009} and \cite{leBerre2010} there is no easy solution to extending a SAT solver to handle non-linear constraints.

%%%Real numbers must be truncated to fit the integer representation. 

%%%Only one solutin can be chosen so product orders are randomly selected to a degree, this can be mitigated by having no stochastic elements in the algorithm

%%%No criterion can be of a partial order though through product composition the problem can be a partial order

%%%The only aggregation of numbers between integers is addition.

%%%It is too expencive to recalculate cardinalities for each component given a specific solution, therefore the cardinalities of a component should be solution independant

\subsection{Verification}
%%%We entered this solver into two Mancoosi MISC competitions

%%%In the first competition we had only partially implemented much of the functionality, so we did not expect great results.

%%%In some instances we where returing non optimal solutions, The bug where we had to add all package versions of all components. 

%%%These problems where fixed, through comparing the results we had gotten from the competition with those from other solvers.
%%%We created our own miny competition which we ran to also ensure that time limits where adhered to.

%%%In the second competition we had fully implemented the solver and this allowed us to enter all tracks with EXCELLENT results

%%%The paranoid track

%%%The trendy track

%%%The user track




