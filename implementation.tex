\chapter{Implementation}
\label{implementation}
\epigraph{What I cannot create, I do not understand.}
{\textit{Richard Feynman, 1988}}

%%%CDR Has been shown to be NP-Complete to find a solution and NP-Hard to find an optimial one.
As presented in the previous chapter, the problem of evolving a component system was shown to be NP-Complete, and the problem of finding an optimal evolution was shown to be NP-Hard.
Therefore, to automate this complex evolution process it will require an efficient algorithm and implementation to not only find satisfiable solutions, but also optimal ones. 

%%%The efficiency of the implementation is important as the problem can combinatorially grow into a hard problem 
The efficiency of the implementations is necessary for many instances of CDR problems.
The goal of many component models is to have large amounts of components with support creating multiple versions of each component.
This directly makes the complexity of evolution grow in a combinatorial manner, making any ad-hoc or overly simple CDR implementation quickly overwhelmed.
The CDR algorithm should then be implemented to be robust and fast.

%%%Formally it resembles the SAT problem, which already has efficient implementations, and has been used to solve this problem
The formal representation of this problem was presented as a set of constraints that must all be satisfied in order for a component relationships and the user request to be fulfilled.
This structure closely resembles the Boolean Satisfiability Problem (SAT), which has fast, robust solver implementations that can be used.
This has been noticed by other researchers \citep{leberre2008,Mancinelli2006} 
and the use of SAT solvers to implement CDR in both academia \citep{abate2011} and industry \citep{leBerre2010} has become common.

%%%Finding the optimial solutions requires extensions to SAT solvers
The finding of an optimal solution though is difficult when using a ``pure'' SAT solver, as it cannot easily represent constraints relating to criteria. 
However, through extending the SAT solver implementations to also handle other types of constraints, such as pseudo Boolean constraints, optimisation becomes significantly easier.

%%%In this chapter\ldots
In this chapter the algorithms and implementation of CDR using SAT solvers extended with pseudo Boolean constraints, are discussed.
First the Davis-Putnam-Logemann-Loveland algorithm \citep{Davis1960, davis1962machine} and its extensions, which are the basis for many current SAT solvers, are described.
This will give a basic understanding of the internal workings of current SAT solvers.
The specific implementation of Eclipse P2 and P2CUDF by \cite{leBerre2010} is then described,
this is given as a comparison of a current technology used by CDR implementations.
Then the description of this research's CDR implementation, GJSolver, is given.
The specific reason for the necessary changes, the differences from other solutions, and the advantages to using it.
This also describes the process in which it was validated and compared against other solvers in the MISC 2011 competition.

\section{Boolean Satisfiability Solvers}
\label{impl.SAT}
Boolean satisfiability (SAT) is the problem of determining if the variables in a Boolean equation can be assigned in such a way that the equation returns true.
This problem was the first identified NP-Complete problem, meaning that no known algorithm exists that efficiently solves all instances of SAT problems.
It has been used previously in this thesis as a means in chapter \ref{formal} as a means of showing component evolution as being NP-Complete.
This also means that many proofs of NP-Completeness is through the reduction to SAT, and therefore many difficult problems have been expressed in the terms of a Boolean equation.
The benefit of this is that algorithms and implementations of programs that solve SAT problems have received significant attention and research to provide solutions to these various problems.
Taking advantage of these algorithms will help with the creation of a CDR implementation that can robustly evolve a component system.

%%%SAT solvers are used to solve many problems, creating a community dedicated to creating fast implenmenations
SAT solvers have been used in various domains to tackle problems such as electronic design automation \citep{Marques-Silva2000}, 
model verification \citep{dennis2006}, and, of course, component system evolution \citep{leBerre2010}.
These uses have caused a great need to create efficient solvers, and this has spawned a community dedicated to creating efficient implementation.
This community, creates and improves their solvers, 
and as a means of validating their creations, regularly compare them against one another in a series of competitions \footnote{http://www.satcompetition.org/}.
Using a competition for progress not only encourages the improvement of solvers for a particular problem set, but also general improvements to the algorithms and heuristics used. 

%%%In this section a common implementation of SAT solvers is discussed, the DPLL algorithm
In this section, first a brief definition of the SAT problem is described, this defines much of the terminology in this domain used in the description of algorithms and implementations. 
Then a short description of the DPLL algorithm is given, this algorithm is the basis of most current SAT solvers and therefore is required knowledge to discuss current implementations.
A common variant of the DPLL algorithm in current SAT algorithms is the alteration to become conflict driven,
this alteration is presented and discussed.
The extension of this algorithm with Pseudo-Boolean constraints is then described,
as this extension allows for more complicated optimisation problems to be represented.
Finally, other methods of solving SAT problems are briefly discussed to give a broader description of the domain. 

\subsection{The SAT Problem}
As described above, the goal of a SAT algorithm is to find whether a set of variables in a Boolean equation can be assigned values in such a way as to make the equation equal true.
A common representation of such a formula is in Conjunctive Normal Form (CNF), this is defined as a conjunction of clauses, 
where each clause is a conjunction of literals, e.g. $(a \vee b) \wedge (\neg b \vee c)$.

This CNF representation of a SAT problem can be defined as such:
\begin{defs}
An instance of a SAT problem is a set of Boolean variables $V$ and a formula which is a set of clauses $F$.
Each clause in $F$ is a set of literals, where a literal is a variable $v$ or its negation $\neg v$.
A set of literals is said to be consistent if for any variable $v$, the set does not contain both $v$ and its negation $\neg v$.
A solution to a SAT formula $F$ is a consistent set of literals $P$, such that for every clause in $c$ in $F$ there exists a literal in $c$ that is also in $P$.
If there exists a $P$ that is a solution of a SAT formula $F$ the problem is said to be satisfiable, otherwise it is unsatisfiable. 
\end{defs}

That is, a SAT problem can have the variable $\{a,b,c\}$ and the formula $\{c_1,c_2\}$, where clauses $c_1 = {a,b}$ and $c_2 = {\neg b, c}$.
A solution for this problem could be $\{a,\neg b,c\}$ as $a \in c_1$ and $\neg b \in c_2$.
However $\{a, \neg b, b\}$ is not because it is not consistent, and $\{a, b, \neg c\}$ is not because it does not contain a literal in $c_2$.  

This definition also follows some classical logic rules, such as literals and their negation can be defined as $\neg \neg v = v$.
This rule can be extended to sets of literals where given a set of literals $P$, $\neg P = [\neg v \mid v \in P]$.

\subsection{Davis-Putnam-Logemann-Loveland algorithm for SAT Solvers}
%%%A successful algorithm for solving SAT problems is the DPLL algorithm, here we describe it in overview
The Davis-Putnam-Logemann-Loveland (DPLL) algorithm \citep{Davis1960, davis1962machine} for solving SAT problems is a complete (meaning it will find a solution if one exists), 
backtracking-based search algorithm for SAT problems represented in conjunctive normal form (CNF).

It runs by assuming a variable from the Boolean formula is true by adding it to the set of literals $P$ then calling itself to find if this new assignment is a solution.
It first takes this new set of literals and calculates all the infered literals in a process called unit-propagation. 
If this new set of literals contains a contradiction then the assumption was incorrect and it returns false, and negates the assumption to continue searching.
However, if this assumption leads to a solution it then returns true, as it has found a solution that satisfies the  formula.

The DPLL algorithm in defined in figure \ref{impl.DPLL} as presented in \cite{dixon2004automating}:
\begin{figure}[h]
\begin{center}
\begin{alltt}
function DPLL(\(F, P\))
   P = unit-propagate(\(F, P\))
   if \(P\) contains a contradiction:
       then return false;
   if \(P\) is a solution to \(F\):
       then return true;
   \(l\) = decide\((P)\);
   if DPLL\((F, P \cup \{l\})\)
       return true
   else
       return DPLL\((F, P \cup \{\neg l\})\);
\end{alltt}
  \caption{Recursive DPLL algorithm}
  \label{impl.DPLL}
\end{center}
\end{figure}

The first \verb+if+ branch of the DPLL algorithm finds if partial assignment $P$ is consistent, if it is not it returns false.
The second \verb+if+ branch determines if the assignment $P$ is a solution to $F$, this would end the search by returning true.
The \verb+unit-propagation+ function and the \verb+decide+ function are both described in the following sections. 

\subsubsection{Unit Propagation}
The first part of this function is the call to infer new literals given the current assignment, this is known as unit-propagation.
Given a possible assignment, a clause is called unit if the assignment does not contain one literal, and contains all of its other literals negation.
That is, given an assignment $P$ and a clause $c$ if $|c \backslash \neg P| = 1$, then $c$ is unit.
A unit literal is then defined given a unit clause as the literal $l$ where $ c \backslash \neg P = \{l\}$.

This notion of ``unit'' allows a literal to be inferred to be in the solution given a current assignment.
For instance, given a formula $\{c_1,c_2\}$, where $c_1 = {a,b}$ and $c_2 = {\neg b, c}$, and the assignment $\{\neg a\}$;
clause $c_1$ is unit and literal $b$ is unit as $c_1 \backslash \neg \{\neg a\} = c_1 \backslash\{ a\} = \{b\}$.
Through unit propagation, $b$ can be inferred to be in the solution, as it must be to make $c_1$ true.
Therefore the assignment is extended to $\{\neg a, b\}$.
This new assignment then makes $c_2$ unit, which through unit propagation infers the assignment be $\{\neg a, b, c\}$, and so on.

The process of unit propagation is further defined in figure \ref{impl.propagation}
\begin{figure}[htp]
\begin{center}
\begin{alltt}
unit-propagate(\(F, P\)):
    while P is consistent and there exists a \(c \in F\) that given \(P\) is unit:
        \(l\) = unit literal in \(c\)
        \(P\) = \(P \cup \{l\}\)
\end{alltt}
  \caption{Pseudo code of Unit Propagation}
  \label{impl.propagation}
\end{center}
\end{figure}

\subsubsection{Literal Order}
The function \verb+decide+ returns a literal that is not unit, nor whose negation is unit, i.e. given $l =$ \verb+decide+$(F)$, $\{l\} \not \in F$ and $\{\neg l\} \not \in F$.
This literal is then added to the formula and checked for satisfiability.
If the formula is not satisfiable, then the negation is added to the formula and checked for satisfiability.  
The order in which the variables from the formula are selected will have a great impact on the speed at which the algorithm finds the formula to be satisfiable or not.
This function will be described further in this chapter, as it clearly has a large impact on the DPLL algorithms use.


\subsection{Advancements in SAT Solvers}
Though the DPLL algorithm is the basis of most modern SAT solvers, the actual implementations have been altered to increase efficiency.
A common change is to alter it from being a recursive propagation based algorithm to a conflict driven, clause learning algorithm.
This modern variant, analyses the reasons for conflicts that occur during the search, and then creates new clauses in order to prune the search tree efficiently.

This particular conflict driven DPLL algorithm is based on MiniSAT, presented by \cite{een2003}.
This implementation was built for efficiency and simplicity, and provides a basic description of the important aspects of such algorithms.

The initial instruction in this algorithm is to create a set denoted as the \verb+trail+.
This set stores pairs of literals and the reasons for their assignment to be used in the analysis.
This trail is typically implemented as a stack for efficiency reasons, though here for simplicity it is represented as a set.
It contains the literals which have either been inferred through propagation paired with the clause which caused their propagation.
It also stores the literals assumed through the \verb+decide+ method, paired with the empty set $\emptyset$.

The set of literals in the trail will be denoted as \verb+trail.lits+, that is \verb+trail.lits+ $= [l \mid (l,r) \in $ \verb+trail+$]$. 
The goal of this algorithm is to populate the \verb+trail+ such that \verb+trail.lits+ is a set of literals that satisfy $F$.

The functions of \verb+propagate+, and \verb+decide+ have been altered slightly from the original DPLL algorithm, though are still in essence the same.
The additional functions of \verb+analyse+ and \verb+backtrack+ give this algorithm a more efficient means of searching for a formula's satisfiability.

\subsection{Pseudo-Boolean Optimisation of SAT Solvers}
%%%Optimisation of SAT solvers is typically done through extending their possible constraints to include Psuedo Boolean inequalities

%%%Then through repeatdly finding a solution then adding a constraint to ensure the next solution is at least as good, the best solution is found

%%%Further optimisation can be made through quickly finding a satisfactory solution, this reduces the space in which to find a better solution

\subsection{MiniSat and SAT4J}
MiniSAT presented in \cite{een2003}, is a simple SAT solver implementation written in C, and designed for speed and extensibility.
SAT4J is a Java implementation, and extension, of that is used in a variety of domains as it is fast and thoroughly verified.
Both of these solvers use similar conflict driven DPLL algorithms presetned earlier, and thus are complete, fast and efficient solvers of SAT problems.
This can be seen, as both solvers have regularly been entered into SAT solving competitions, where their results are excellent.

\subsection{Other Methods}
This \cite{Stuckenholz2007} study looks at using boolean optimisation with branch and bound as a solution, as does \cite{Jenson2010a}.


\subsubsection{Integer Programming}
%%%Discussion of this method as the best MISC solver uses this, it has a very complex implementation
\subsubsection{SMT Solvers}
%%%SMT Solver, a slightly higher logic than SAT uses; it has to broad a definition when SAT suffices
\subsubsection{Constraint Solver}
%%%We could just use Prolog, like SMT I think it is too broad when there are good SAT solvers


\section{GJSolver}
%%%My Implementation, cut the fat, straight forward
Through the course of this research an implementation grew out of the need to have a modifiable base to experiment with component dependency resolution.
Other implementations of CDR where often platform specific, or involved difficult (or impossible) to modify code.
This CDR implementation is know as GJSolver, and is directly designed to solve CDR problems represented in CUDF, with optimisation descriptions in Mancoosi format.

SAT4J was used as a base for the satisfiability, where minor non-critical code was altered in order to interface with it correctly.


\subsection{Product and Lexicographic orders in Pseudo-Boolean Optimisation}
%%%Here we descirbe the mapping from our Optimisation framework to PBO, product order is easy, lexicographic requires some muddling

\subsection{Drawbacks of this Optimisation approach}
%%%There are a few drawbacks to this mapping;
%%%These simplifications are mostly necessary for this problem as it keeps the problem manageable,
%%%and including all aspects of our formal optimisation framework would be practically impossible

%%%The optimisation must be represented linearly
As noted in \cite{le_berre_dependency_2009} and \cite{leBerre2010} there is no easy solution to extending a SAT solver to handle non-linear constraints.

%%%Real numbers must be truncated to fit the integer representation. 

%%%Only one solutin can be chosen so product orders are randomly selected to a degree, this can be mitigated by having no stochastic elements in the algorithm

%%%No criterion can be of a partial order though through product composition the problem can be a partial order

%%%The only aggregation of numbers between integers is addition.

%%%It is too expencive to recalculate cardinalities for each component given a specific solution, therefore the cardinalities of a component should be solution independant

\subsection{Verification}
%%%We entered this solver into two Mancoosi MISC competitions

%%%In the first competition we had only partially implemented much of the functionality, so we did not expect great results.

%%%In some instances we where returing non optimal solutions, The bug where we had to add all package versions of all components. 

%%%These problems where fixed, through comparing the results we had gotten from the competition with those from other solvers.
%%%We created our own miny competition which we ran to also ensure that time limits where adhered to.

%%%In the second competition we had fully implemented the solver and this allowed us to enter all tracks with EXCELLENT results

%%%The paranoid track

%%%The trendy track

%%%The user track




