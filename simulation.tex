\chapter{Simulation}
\label{simulation}
{}To evaluate different strategies when evolving a component systems, the environment in which these evolutions occur is simulated.
{}Through modelling then simulating the different aspects of a system; the user-interaction, the repository, and the resolver;
{}conclusions can be drawn on the benefits and draw backs of a particular evolution strategy.

{}The motivations for simulating and the methodology used to create the simulation are presented in this chapter.
{}The result of this chapter is a simulation that can be used to predict how a component system will evolve given different variables of the user and the strategy they use.

\section{Why Simulate?}
%%%Why are we using a simulation instead of real systems, or a controlled environment
To evaluate an evolution strategy some options include;
using a set of actual systems with real users could be accessed to collect field data;
creating a controlled environment in which users are given tasks and monitor the outcomes;
simulating a systems evolution through creating models and altering environment variables to study their effects.
In this section we discuss the positive and negative aspects of each of these approaches,
and present the reasons for the selection of the simulation methodology for this research.

%%%The pros and cons of using real systems with real users
Using real systems with real users would clearly produce real and valid data to be studied and analysed to find the best evolution strategies.
Solvers could be developed and distributed to different users, each solver using different criteria 
and as each user has different behaviours (amount they install, when they update)
these results could be analysed to find strategies that produce good systems. 

%%%Now the cons
This approach will create very accurate research, however it has some significant drawbacks,
it will take significant periods of time to create meaningful results, for each day of results you have to wait a day.
Finding the way a particular strategy effects a system over an entire year, will mean waiting a year.
More significantly, finding users that will trust an experimental system to alter their real system would be extremely difficult.   
A user will likely not trust a newly released resolver, as their system is important to them and even the slightest error can cause
a system to become unstable.

%%%Users trust is difficult to gain
To gain the trust of possible users the experimental resolvers would have to be thoroughly tested through a repositories development cycle and be well maintained.
Moving a package through this cycle can be itself a massive undertaking lasting several months. 
For example Eclipse Plug-ins it involves going a component going through four phases 
Proposal, Incubation, Mature, and Top-Level\footnote{http://www.eclipse.org/projects/dev\_process/development\_process\_2010.php};
similar to Debian's process of moving through the phases Unstable, Testing, Frozen, and finally stable\footnote{http://en.wikipedia.org/wiki/File:Debian-package-cycl.svg}.
After it has been through this cycle, maintenance of the resolver is still required; 
for instance the Ubuntu package ``apt'' has released about 2 changes a month\footnote{http://changelogs.ubuntu.com/} to it or related packages since its initial release.
This shows how much effort must be applied to earn a users trust, and this effort will likely outweigh the actual benefits.

%%%The pros and cons of using real users with pseduo systems
A study of users interacting with a system in a monitored and controlled environment could be executed.
Each user could be given different strategies, e.g. solver criteria, and different tasks to perform on their system to approximate real interactions.
This study could compress a years worth of interactions with a system into an hour, and produce results from real users. 
Compared to the previous type of study using real users with real systems,
this research removes the necessity of user trust as the user is altering a system that is not theirs,
and results can be gained in hours not years. 
However, it will also produce less valid results, as it is still an approximation of a real system, and the users know this.
Any controlled environment would alter how the user interacts with their controlled system, making the results less reliable.
For example, a user typically researches a package before selecting installing it because it would have real implications, 
in a controlled environment these implications are removed so the selection would still be of questionable validity.

The largest problem with this method is again finding enough users.
With the previous method it was trust that would limit the user count, here it is the effort to find and monitor the amount of necessary users required.
For example, given we want to test 10 different strategies with 5 different user types, each combination must contain multiple different test subjects to find statistically significant results, 
and each subject taking upwards of an hour to complete the study. 
This would be a significant effort to organise users, monitor interactions and collect results, so much so that that it may be logistically impractical when compared to the benefits.

%%%Instead we can simulate, with an approximation of the real world.\\ 
%%%When drawing conclusions the accuracy of this approximation must be considered, therefore significant effort has gone into data collection and validation.
A simulation is a surrogate of the real system, such that it represents the core aspects of a component systems evolution.
This is accomplished through modelling the most important parts of the system, 
and computationally creating and measuring the results. 
As the simulation is only an approximation of the real world, 
the accuracy to which it actually represents the real world is not 100\%.
The goal is then to make it a ``close enough'' approximation so that the conclusions drawn from it are valid in the real world.
So when analysing the results and forming conclusions, we must take into account the assumptions we have made creating the simulation to determine 
the conclusions overall accuracy.
Therefore, the majority of the effort when creating a simulation is gathering and using valid information when making assumptions.

%%%What is good about the simulation over the other two methods, speed at which results are generated, the cost to get the results, the control over the variables in the simulation.
Simulation is superior to either using real users and real systems, or using a controlled environment in the speed at which hypotheses can be tested and evaluated,
the cost to test and get results, and the control over variables and configuration of the environment.

%%%Speed at which results are generated
As the speed increases at which a hypothesis can go from being an idea on paper to being tested in a real or simulated environment, increased the amount of meaningful information can be generated. 
When an idea is proposed as a possible solution to a problem, the quicker that idea can be eliminated or encouraged allows new ideas to be formed off of the original.
These ideas themselves can then be tested, to see if they are suitable solutions.
The faster this process is, the ideas can be tested, the better solutions and more information is generated.
Using real users, or real systems, requires long periods of waiting, where if the actions and environment can be modeled and executed computationally there is little waiting.
Through simulation an idea can be tested almost immediately by simultaneously evolving multiple simulated systems, where using a real user, 
it may take days or months to generate the same amount of results.  

%%%Cost
The cost of using any of these methods can be measured in the amount of time it would take in organising, measuring and wasted time, for the the results to be collected.
Using a real user and system would involve an enormous amount of time validating and distributing the solvers (as discussed earlier), 
and the controlled environment would require many hours of organisation and planning to gather the necessary users, and then measure their interactions with the system.
However, with a simulation the main effort is ensuring that the models are accurate enough to gather meaningful results.
This time in validating the simulation and associated models is only necessary once, 
i.e. if more results are needed the simulation will not need to be re-validated.
The other two methodologies do not have this property, as for each user tested and measured will be a duplicate effort. 

%%%Control
The control over the results that a simulation returns far exceeds the other methods as models can be altered and tested where a real user cannot. 
This control allows the testing of extreme situations, the sensitivity analysis of different variables,
and the generation of possibly optimal but 'out of the box' ideas. 
For instance, the testing of the amount of days a user waits between updates can be tested through altering the times between updates, then running the simulation.
If real users where used, the amount of users necessary to be collected would be enourmous to produce any significant results in this area.

%%%Final words on why we simulate
A simulation was used as it provides us with a cost/benefit ratio that is desirable, while potentially allowing an appropriate level of accuracy to draw meaningful conclusions.
The main effort is then to create the simulation with valid models that will give us the desired accuracy.

\section{Methodology}
%%%We use the methodology from `` Build a Valid and Credible Simulation''
{}A goal of this study is to create a reusable simulation for future use, and to provide useful information on the process of component evolution. 
{}This places validity and credibility of a simulation and the results it provides at a high priority.
{}To create such a simulation the methodology outlined by \cite{Law2005} in ``How to build valid and credible simulation models'' is followed.
{}This methodology is a guideline for defining the study, collecting information, creating and validating models, and running the simulation.
{}In this section we introduce the methodology with its goals and how they are aligned to ours, 
{}discuss the steps that it recommends to be taken to create a valid simulation, and how the simulation will be created and what it will produce for this study.

\subsection{Validation and Credibility}
%%%Why do we use this methodology and how is it relevant?
This methodology was created after the observation that validation was often ``attempted after the simulation models had already been developed'',
and that the validation may of only occurred only if there was money and time left at the end of the project.
However, such simulations, that are not validated, can produce erroneous information that leads to incorrect, possibly costly and bad decisions being made.
This reduces the credibility of the simulation to be used in future as a tool.

%%%What is a valid simulation?
A simulation is an abstraction and simplification of reality, usually created as using an actual system can be disruptive, not cost-effective, or simply impossible.
In this context ``\textit{Validation} is the process of determining whether a simulation is an accurate representation of the system, for the particular object of the study.''
So a valid simulation if an abstraction that accurately represents a system closely enough for an objective of a study to be completed.
The later part is an important aspect of validation, as the accuracy of the simulation is directly dependent on the problem and questions the study addresses.
A simulation that is 99\% accurate may cost significantly more to produce than one that is 90\%, but provide little additional benefit given the specific information wanting to be gained from it.
Therefore an important aspect of the simulation is the definition of the problem, as it will lead to the definition and scope of the simulation.

%%%What is credible
A simulation, and by extension its results, have \textit{credibility} if key stakeholders accept them as ``correct''.
A credible model is not necessarily valid, and vice-versa, as it involves the input of a person who decides if level of accuracy and the goal the simulation have been obtained.
This requires an understanding of the models and simulation by key personale and therefore their direct input and involvement with the project.

The simulation produced by this study to identify the effect of different strategies on the evolution of component systems must be validated to produce meaningful results,
and must be credible for these results to be trusted.


\subsection{7 Step Method}
This methodology has a 7 step approach to creating a valid and credible simulation that will be described here.
These steps are; formulating the problem; collecting information and data to construct a conceptual model; validating the conceptual model;
implementing (programming) the model; validating the programmed model; designing, conducting and analysing experiments; and documenting and presenting the simulation results.

\subsubsection{Step 1: Formulate the problem}
The first step is to formulate the problem as clearly as possible, this is usually done with core stakeholders in a ``kick-off meeting''.
The core artifacts from this step are the overall objectives of the study, specific question wanting to be answered, scope of the study,
 and different configurations of the simulation with the measures used to evaluate their performance. 

\subsubsection{Step 2: Collect information and Data to Construct Conceptual Model}
The conceptual model is a description of how the simulation and system work, relative to the problems earlier defined.
It is the most important artifact of the simulation, as it should be high level enough to be understood by the core stakeholders
and be reused in future simulations.
It is created through interviews with subject matter experts, collecting data like procedures and results from similar exiting systems, and other sources of relevant data.
Problems like the data not being representative of the model, not being in the appropriate format or type, and containing errors must be handled before use.

The conceptual model also contains all of model parameters including the documented assumptions. 
It is defined to the level of detail given, project objective, performance measures, data availability, computer constraints, resource constraints.

\subsubsection{Step 3: Conceptual model Validation}
The conceptual model is the most important aspect of the simulation, thus its validation will be through.
The core method used to validate this model, is to discuss the it with core-stakeholders and subject matter experts.
This provides feedback as to the direction of the conceptual model, ensuring that it will answer the questions posed in the study.

\subsubsection{Step 4: Implement the Models}
The implementation of the simulation models must also be executed and documented in a way that allows other to replicate and repeat the process.
The artifacts created during this process must be verified to work correctly, this can be accomplished through test-cases and debugging.

\subsubsection{Step 5: Validate Implementation}
There is no completely definitive approach to validating the simulation,
however, the most definitive test of a simulations validity is established by closely looking at the outputted results compared to that from an actual system \cite{Law2005}.

This is done through:
\begin{itemize}
  \item \textbf{Results validation: } a comparable system is used to create results and compared with the results from the simulation for validation.
  \item \textbf{Face Validation: } experts are given output of the simulation model and checked to see if it is consistent with how they percieve the system should operate.
\end{itemize}

Further validation of the implementation can be accomplished with sensitivity analysis,
which is performed on the simulation to find the factors with the greatest impact on the performance and results.

\subsubsection{Step 6: Design, Conduct and Analyse Experiments}
For each of the configurations, decisions must be made about the time given to them, the number of independent runs to return statistically significant results.
At the end of this step, after the results have been analysed a decision must be made if additional experiments are to be run,
as either the results are inconclusive, or other aspects of interest have arisen.

\subsubsection{Step 7: Document and Present Results}
This step involves the presentation of the model to the core-stakeholders in a manner that describes the concept model, the simulation and the results.
This step is critical for the future re-use of the model, as is the detailed description of the validation process to promote credibility.


\subsection{Differences in methodology}
To produce a valid and credible simulation study is the goal of using this methodology.
However, this methodology has been created for industrial projects with of a larger scale; for instance the U.S.A. Department of Defence.
As this study is smaller in scale in time and effort that many other simulation projects, some of the procedures recommended in this method have been restricted and some removed.
The most significant difference to the methodology is the clear definition between decision-maker and simulation designer.
In this project these all refer to a single person, therefore meetings between these people are superfluous.
Other people in the project including subject-matter experts, core-stakeholders, simulation analysts consist of survey participants and
project supervisors, because the limits of the projects resources excludes employment of experts.
This may reduce the validity of the end model, but these restrictions have been made when only necessary,
and done so in a manner that attempts to minimise negative effects.


\section{Simulation artifacts}
We have used this methodology to create a simulation that is independent of the component model and system we want to simulate in this study.
This has been done to make the simulation reusable in different contexts in order to test if the conclusions drawn from this study are component model/system independent.
As such in this chapter we describe the independent parts of the simulation, and leave the dependent parts for chapter \ref{ubunutsimulation}.

The independent parts of this simulation include the problem definition, the conceptual model with it's component parts;
the user model, the solver model and the repository model.
The configuration of these models to answer the question and the implementation of the simulation are also discussed.

\subsection{Problem Definition and Conceptual Model}
To create our conceptual model, we must first precisely describe the problem;
The problem addressed in this entire study is that of the effects of component evolution.
The key question that are asked is
``What effect does using component resolution given a set of criteria have on a component system?''.
To answer this requires knowing about the criteria used to find the resolved systems, the repository where components are accessed,
and the user and their actions.
The conceptual model is then created from separate models, the user model, the solver model, and the repository model.

\subsection{User Model}
The user model involves many aspects, including the life-cycle of specific actions, the probability of actions being taken, and also the parameters of an action.
A user can typically execute many different types of actions, install, remove or upgrade a component, upgrade the entire system,
download a source for a component, change the status of a package, automatically remove package that are not necessary, or even format the system and start again.
In our abstraction of reality the user has two actions with the resolver, either to install a new package or to try upgrade the entire system.
These two action were selected as they represent the core interactions the user performs on the system.
The initial system that is 

%%%Update
Probably the most executed action by the user is the request to update the system.
This involves looking at the repository and trying to find newer versions of currently installed packages to replace the current versions.
This is done either because newer versions have increased functionality or have fixed bugs,
however can become quite complex as newer versions of component may conflict with other packages, therefore are not able to be installed.
The update action can happen at regular intervals as it is typically automated or part of a users routine.
These intervals can be quite quick, daily for many users, 
and they can be over an extended period of time, 
as with server administrators not wanting to change a potentially critical system.
In this abstraction, the core variable for a users update action is the cycle in which it occurs,
e.g. every 3 days the user updates.

%%%Install
Installation if the request a user performs to extend the functionality of the system they are using.
A user selects a package with the required functionality they desire, usually to complete a task,
then the resolver installs a system that allows that package to be used.
Determining the probability a user will select a component to be installed is difficult given the enormous amount of factors this relies on.
The users job, location, current tasks, previously installed software, favourite colour\ldots all may effect when and what package a user selects to install.
Given that all this information is impractical to simulate, we abstract this problem into the form of two questions;
what components may a user select to install and how likely would a user select to install these.
This is represented by a weighted list of components, where the weights represent popularity,
e.g. package ``A'' has a 10\% chance of being selected as the package to install, package ``B'' has a 5\% change \ldots

The next question is what is the probability that a user will install a package, and how many packages?
This is represented by a probability for the amount of packages that a user may install on a day,
e.g. they have a 80\% chance of installing nothing, a 15\% chance of installing one pace

%%%The initial system to start from
The initial system the user has installed before the component simulation of evolution commences can have a direct effect on the results.
Many systems will release different configurations of components that use the same repository, as this is a typical use of components to create systems with different use cases.
The Eclipse framework offers more than ten types of initial Eclipse installs for different users.
The Ubuntu system offers at least three different (server, desktop, alternative) each for either amd64 or i386 chipsets.
The selection of the initial system can depend on many aspects of the simulation, 
though selecting the most popular installed system may result in broader results. 

A user model is then represented by 4 pieces of information,
\begin{enumerate}
  \item  The cycle at which a user selects to update a system
  \item The probability a user will select a package to be installed
  \item The probability a user will select to install a package per day
  \item The initial system
\end{enumerate}


\subsection{Solver Model}
The solver selected to resolve the package dependencies is an important aspect of this simulation.
Throughout this thesis we have discussed the definition, implementation and extension of a component dependency resolver.
The core aspect we have focused on is the variable criteria that can be used to find different optimal solutions given the requirements of a system.
Given the possible actions a user can take in this user model, update or install, each have different objectives in the system,
they also require different criteria to optimise for.
While the update action tries to upgrade the entire system, 
the install action may require the newest version of a package to be installed but would typically not update the entire system to do it. 

The solver model then contains this information:
\begin{enumerate}
  \item The criteria to optimise for when the user updates the system
  \item The criteria to optimise for when the user installs a package
\end{enumerate}

\subsection{Repository Model}
The repository model is an abstraction of the server which contains and distributes the packages to the client to be installed.
The repository is a key component in the study of component system evolution, 
as the user actions, of update and install, are dependent on the repository and the solver model must consider all packages in the repository when finding the optimum system.
This model is the most complex of the three, however it can be simplified by removing the distribution concern.
It is a very difficult model to create and is recommended that real data be used,
and assumptions also have to be made to maintain the consistency of this model.

%%%It is very complex and we need daily data
A repository of components contains all of the information of the component interaction, and component versions.
What is in the repository at any given time is then dependent on the contained components life cycles,
as each of these is a complex entity in itself, the state of the entire repository is difficult to predict.
This complexity that is created over time in the repository is an aspect that clearly effects the evolution of a component system.
Therefore, this simulation takes into account the date, by identifying the set of components that exit in the repository on a given date.

%%%Distrubution details are ignored
As the distribution, and aspects like the protocol or network used to transfer the packages, are not core issues of component system evolution,
they will not be simulated.
This is then the assumption that the repository is always accessible by the solver with no faults at all times during the simulation.
This is clearly not the case in reality, as servers and connections can be intermittent,
however, removing this aspect greatly reduces the complexity of the model without a negative impact on accuracy. 

%%%This accuracy is difficult to create
A repository built through using algorithm would be difficult to validate as being an accurate representation of an actual repository.
The amount of factors that would have to be considered to define an accurate representation, the algorithm to build such a repository,
and the method in which you can validate it's accuracy,
are all difficult problems, and outside the scope of this study. 
Therefore, in this simulation it is recommended that a data from a real repository is used.
This in itself is a difficult task to accomplish, especially as daily information on a repositories state means that accurate records have to of been kept on a artifact that is constantly in flux.

%%%The range of time in which to look at
The range of time over which the simulation is run will determine the repositories that are required.
It is also important as it should be long enough to draw conclusions from,
but as the simulation can take considerable resources to execute, too long and it may make it impractical to execute all the iterations necessary.
Other external aspects such as policy changes in the way in which a repository is run, or release cycles of the component system, 
may have an effect on the internal properties of the repository.
This must also be considered when defining the time range, if not excluded then understood when analysing results.
Selecting of the initial system also relies on the time frame that was selected,
as all the components in the system must be ensured to also be in the repository.

%%%You can never remove a component from the repository
This model has two core assumptions that must be mentioned; a repository may never remove a package, and a package version is static and may not change.
This is clearly not a constraint that exist in reality as when releasing a newer version, many repositories (e.g. Eclipse) will remove out dated packages,
in some cases the repository will only contain the most uptodate packages.
Although rare, the changing of a package version may occur in some repositories, here though it is a strict constraint.
These assumptions are to ensure the consistency of the repository and it's packags to enable their use by the solver, 
as the repository in this simulation stores all information about the packages.
Having all packages are always in the repository ensures a case where a package is in a system but not in the repository is impossible,
and making sure a package version never changes ensures that information between the system and repository is synchonised.  

%%%this model contains a record of packages in repository over time
This model then contains one set of information:
\begin{enumerate}
  \item A daily record of package versions and their dependencies stored in a repository
  \item A time frame, start and finish, over which the simulation is run
\end{enumerate}

\subsection{Configuration}
%%%A configuration is the set of parameters of the simulation. What are these parameters which we must consider.
A configuration is the set of variables which define the parameters of the simulation.
How these variables are defined are derived from what goals of the specific simulation.
What the invariants are and how the variables are altered depends on the questions being asked, and the approach to answering them.

In this conceptual model there have been defined 8 different dimensions to alter this simulation by:
\begin{enumerate}
  \item The cycle at which a user selects to update a system
  \item The probability a user will select a package to be installed
  \item The probability a user will select to install a package per day
  \item The initial system
  \item The criteria to optimise for when the user updates the system
  \item The criteria to optimise for when the user installs a package
  \item A daily record of package versions and their dependencies stored in a repository
  \item A time frame, start and finish, over which the simulation is run
\end{enumerate}

These variables can be altered in many different ways to answer important and relevant questions to do with component evolution.

\section{Simulation implementation}
%%%Here we describe how our simulation is implemented, the processes in which the implementation is executed
How the simulation is implemented will effect the scalabliliy and the reusability of the end product.
It may also effect the results that are returned, as the order in which aspects of the conceptual model are calculated may matter.
Therefore, a detailed description of the implementation is given in hopes that it is able to be reused.

This simulation has been implemented as independent from the variables mentioned above, making it as reusable as possible.
The core process is implemented using a series of scripts written in BASH and Python,
these have been abstracted to pseudo code and presented here.
As the simulation requires no external input it can be discussed as a simple input, process, output operation,
where there are a set of inputs, returning a set of results.

%%%Input
The input to this simulation is the configuration described previously.
The format for all processes on descriptions of sets of components is handled in the CUDF format,
so the initial input will be a set of repositories, each with components that existed in it at a given date.
The next input will be a start date given in seconds since the epoch (Jan. 1st 1970) and a length in days that the simulation should run for, this is the time frame of the simulation.
The user update cycle, the weighted package and the user install distribution are defined in their own formats discussed below.
The criteria for updateing and installing are defined in the format discussed in chapter \ref{criteria},
and the initial system is defined in the CUDF format.

%%%Process
The process is to first to generate some user files that details the actions that users may of take on the system.
Then for each of these users, we process each day, and given the actions they would of executed on that day we generate a CUDF problem,
then pass it to the solver with the appropriate criteria for that given action.

%%%Output
The output of this simulation will be a series of CUDF files for each user when ever a change was made to a system over the time given.

The specifics of the process to generate the different user files, then to execute their actions is complex, is complex and 
has a few assumtions that require further explanation.

\subsection{Generate User Actions File}
The generate users script input is:
\begin{itemize}
  \item a start date 
  \item a length of days 
  \item a set of install distributions
  \item a set of weighted components 
  \item an update cycle line 
  \item a number of random users to create
\end{itemize}

\begin{figure}[htp]
\begin{center}
75.0, 18.0, 5.0
73.0, 18.0, 6.0, 1.0
54.0, 34.0, 9.0, 2.0
\caption[Install Distribution Example File]{An exmaple of a usres installation distributions}
\label{userfile}
\end{center}
\end{figure}

\begin{figure}[htp]
\begin{center}
synaptic,1840590
firefox,1828354
software-properties-gtk,1781797
gnome-system-monitor,1771676
gucharmap,1770369
\caption[Weighted Package File Example]{An exmaple of a Weighted Package file, co }
\label{userfile}
\end{center}
\end{figure}

A user file can be defined given the grammer
time;[install:PACKAGE[,PACKAGE]*]?;[keep:PACKAGE[,PACKAGE]*]?;[update]?

\begin{figure}[htp]
\begin{center}
1258110000.0;;;update
1258196400.0;;;update
1258282800.0;install:vinagre;;update
1258369200.0;install:compiz-core;keep:vinagre;update
1258455600.0;;keep:vinagre,compiz-core;update
1258542000.0;install:gdebi;keep:vinagre,compiz-core;update
  \caption[User File example]{An exmaple of a User file}
  \label{userfile}
\end{center}
\end{figure}

\subsection{Generate CUDF}
The generate CUDF script's input is:
\begin{itemize}
  \item a line from a user file 
  \item a CUDF file of the current system
  \item A set of repositories
\end{itemize}

%check to see if the requested installed package exists in the repository

\subsection{Execute Simulation}
The execute simulation script's parameters are:
\begin{itemize}
  \item a set of repositories
  \item an initial system installation CUDF file
  \item a user file to be executed
  \item criteria used when installing a package
  \item criteria used when updating the system
\end{itemize}

%%%What happens when a install is required that is then not able to be accomplished.

\subsection{Optimisations}

%%%Executing multiple users in a row

%%%Upgrade command in CUDF altered to be upgrade: *

\section{Simulation Validation}
%%%With the methodology there are many pionts at which we validate individual parts/models, and their overall composition.
%%%The main validation method is the inviewing of different stakeholders, this for our method was discussions with supervisors, at conferences, and throught the survey.


\section{Conclusions}
%%%Discuss the overall conclusions. Bullet point the points most surprising, and useful for further study.

