\chapter{Simulation}
\label{simulation}
{}To evaluate different strategies when evolving a component systems, the environment in which these evolutions occur is simulated.
{}Through modelling then simulating the different aspects of a system; the user-interaction, the repository, and the resolver;
{}conclusions can be drawn on the benefits and draw backs of a particular evolution strategy.

{}The motivations for simulating and the methodology used to create the simulation are presented in this chapter.
{}The result of this chapter is a simulation that can be used to predict how a component system will evolve given different variables of the user and the strategy they use.

\section{Why Simulate?}
%%%Why are we using a simulation instead of real systems, or a controlled environment
To evaluate an evolution strategy some options include;
using a set of actual systems with real users could be accessed to collect field data;
creating a controlled environment in which users are given tasks and monitor the outcomes;
simulating a systems evolution through creating models and altering environment variables to study their effects.
In this section we discuss the positive and negative aspects of each of these approaches,
and present the reasons for the selection of the simulation methodology for this research.

%%%The pros and cons of using real systems with real users
Using real systems with real users would clearly produce real and valid data to be studied and analysed to find the best evolution strategies.
Solvers could be developed and distributed to different users, each solver using different criteria 
and as each user has different behaviours (amount they install, when they update)
these results could be analysed to find strategies that produce good systems. 

%%%Now the cons
This approach will create very accurate research, however it has some significant drawbacks,
it will take significant periods of time to create meaningful results, for each day of results you have to wait a day.
Finding the way a particular strategy effects a system over an entire year, will mean waiting a year.
More significantly, finding users that will trust an experimental system to alter their real system would be extremely difficult.   
A user will likely not trust a newly released resolver, as their system is important to them and even the slightest error can cause
a system to become unstable.

%%%Users trust is difficult to gain
To gain the trust of possible users the experimental resolvers would have to be thoroughly tested through a repositories development cycle and be well maintained.
Moving a package through this cycle can be itself a massive undertaking lasting several months. 
For example Eclipse Plug-ins it involves going a component going through four phases 
Proposal, Incubation, Mature, and Top-Level\footnote{http://www.eclipse.org/projects/dev\_process/development\_process\_2010.php};
similar to Debian's process of moving through the phases Unstable, Testing, Frozen, and finally stable\footnote{http://en.wikipedia.org/wiki/File:Debian-package-cycl.svg}.
After it has been through this cycle, maintenance of the resolver is still required; 
for instance the Ubuntu package ``apt'' has released about 2 changes a month\footnote{http://changelogs.ubuntu.com/} to it or related packages since its initial release.
This shows how much effort must be applied to earn a users trust, and this effort will likely outweigh the actual benefits.

%%%The pros and cons of using real users with pseduo systems
A study of users interacting with a system in a monitored and controlled environment could be executed.
Each user could be given different strategies, e.g. solver criteria, and different tasks to perform on their system to approximate real interactions.
This study could compress a years worth of interactions with a system into an hour, and produce results from real users. 
Compared to the previous type of study using real users with real systems,
this research removes the necessity of user trust as the user is altering a system that is not theirs,
and results can be gained in hours not years. 
However, it will also produce less valid results, as it is still an approximation of a real system, and the users know this.
Any controlled environment would alter how the user interacts with their controlled system, making the results less reliable.
For example, a user typically researches a package before selecting installing it because it would have real implications, 
in a controlled environment these implications are removed so the selection would still be of questionable validity.

The largest problem with this method is again finding enough users.
With the previous method it was trust that would limit the user count, here it is the effort to find and monitor the amount of necessary users required.
For example, given we want to test 10 different strategies with 5 different user types, each combination must contain multiple different test subjects to find statistically significant results, 
and each subject taking upwards of an hour to complete the study. 
This would be a significant effort to organise users, monitor interactions and collect results, so much so that that it may be logistically impractical when compared to the benefits.

%%%Instead we can simulate, with an approximation of the real world.\\ 
%%%When drawing conclusions the accuracy of this approximation must be considered, therefore significant effort has gone into data collection and validation.
A simulation is a surrogate of the real system, such that it represents the core aspects of a component systems evolution.
This is accomplished through modelling the most important parts of the system, 
and computationally creating and measuring the results. 
As the simulation is only an approximation of the real world, 
the accuracy to which it actually represents the real world is not 100\%.
The goal is then to make it a ``close enough'' approximation so that the conclusions drawn from it are valid in the real world.
So when analysing the results and forming conclusions, we must take into account the assumptions we have made creating the simulation to determine 
the conclusions overall accuracy.
Therefore, the majority of the effort when creating a simulation is gathering and using valid information when making assumptions.

%%%What is good about the simulation over the other two methods, speed at which results are generated, the cost to get the results, the control over the variables in the simulation.
Simulation is superior to either using real users and real systems, or using a controlled environment in the speed at which hypotheses can be tested and evaluated,
the cost to test and get results, and the control over variables and configuration of the environment.

%%%Speed at which results are generated
As the speed increases at which a hypothesis can go from being an idea on paper to being tested in a real or simulated environment, increased the amount of meaningful information can be generated. 
When an idea is proposed as a possible solution to a problem, the quicker that idea can be eliminated or encouraged allows new ideas to be formed off of the original.
These ideas themselves can then be tested, to see if they are suitable solutions.
The faster this process is, the ideas can be tested, the better solutions and more information is generated.
Using real users, or real systems, requires long periods of waiting, where if the actions and environment can be modeled and executed computationally there is little waiting.
Through simulation an idea can be tested almost immediately by simultaneously evolving multiple simulated systems, where using a real user, 
it may take days or months to generate the same amount of results.  

%%%Cost
The cost of using any of these methods can be measured in the amount of time it would take in organising, measuring and wasted time, for the the results to be collected.
Using a real user and system would involve an enormous amount of time validating and distributing the solvers (as discussed earlier), 
and the controlled environment would require many hours of organisation and planning to gather the necessary users, and then measure their interactions with the system.
However, with a simulation the main effort is ensuring that the models are accurate enough to gather meaningful results.
This time in validating the simulation and associated models is only necessary once, 
i.e. if more results are needed the simulation will not need to be re-validated.
The other two methodologies do not have this property, as for each user tested and measured will be a duplicate effort. 

%%%Control
The control over the results that a simulation returns far exceeds the other methods as models can be altered and tested where a real user cannot. 
This control allows the testing of extreme situations, the sensitivity analysis of different variables,
and the generation of possibly optimal but 'out of the box' ideas. 
For instance, the testing of the amount of days a user waits between updates can be tested through altering the times between updates, then running the simulation.
If real users where used, the amount of users necessary to be collected would be enourmous to produce any significant results in this area.

%%%Final words on why we simulate
A simulation was used as it provides us with a cost/benefit ratio that is desirable, while potentially allowing an appropriate level of accuracy to draw meaningful conclusions.
The main effort is then to create the simulation with valid models that will give us the desired accuracy.

\section{Methodology}
%%%We use the methodology from `` Build a Valid and Credible Simulation''
{}A goal of this study is to create a reusable simulation for future use, and to provide useful information on the process of component evolution. 
{}This places validity and credibility of a simulation and the results it provides at a high priority.
{}To create such a simulation the methodology outlined by \cite{Law2005} in ``How to build valid and credible simulation models'' is followed.
{}This methodology is a guideline for defining the study, collecting information, creating and validating models, and running the simulation.
{}In this section we introduce the methodology with its goals and how they are aligned to ours, 
{}discuss the steps that it recommends to be taken to create a valid simulation, and how the simulation will be created and what it will produce for this study.

\subsection{Validation and Credibility}
%%%Why do we use this methodology and how is it relevant?
This methodology was created after the observation that validation was often ``attempted after the simulation models had already been developed'',
and that the validation may of only occurred only if there was money and time left at the end of the project.
However, such simulations, that are not validated, can produce erroneous information that leads to incorrect, possibly costly and bad decisions being made.
This reduces the credibility of the simulation to be used in future as a tool.

%%%What is a valid simulation?
A simulation is an abstraction and simplification of reality, usually created as using an actual system can be disruptive, not cost-effective, or simply impossible.
In this context ``\textit{Validation} is the process of determining whether a simulation is an accurate representation of the system, for the particular object of the study.''
So a valid simulation if an abstraction that accurately represents a system closely enough for an objective of a study to be completed.
The later part is an important aspect of validation, as the accuracy of the simulation is directly dependent on the problem and questions the study addresses.
A simulation that is 99\% accurate may cost significantly more to produce than one that is 90\%, but provide little additional benefit given the specific information wanting to be gained from it.
Therefore an important aspect of the simulation is the definition of the problem, as it will lead to the definition and scope of the simulation.

%%%What is credible
A simulation, and by extension its results, have \textit{credibility} if key stakeholders accept them as ``correct''.
A credible model is not necessarily valid, and vice-versa, as it involves the input of a person who decides if level of accuracy and the goal the simulation have been obtained.
This requires an understanding of the models and simulation by key personale and therefore their direct input and involvement with the project.

The simulation produced by this study to identify the effect of different strategies on the evolution of component systems must be validated to produce meaningful results,
and must be credible for these results to be trusted.


\subsection{7 Step Method}
This methodology has a 7 step approach to creating a valid and credible simulation that will be described here.
These steps are; formulating the problem; collecting information and data to construct a conceptual model; validating the conceptual model;
implementing (programming) the model; validating the programmed model; designing, conducting and analysing experiments; and documenting and presenting the simulation results.

\subsubsection{Step 1: Formulate the problem}
The first step is to formulate the problem as clearly as possible, this is usually done with core stakeholders in a ``kick-off meeting''.
The core artifacts from this step are the overall objectives of the study, specific question wanting to be answered, scope of the study,
 and different configurations of the simulation with the measures used to evaluate their performance. 

\subsubsection{Step 2: Collect information and Data to Construct Conceptual Model}
The conceptual model is a description of how the simulation and system work, relative to the problems earlier defined.
It is the most important artifact of the simulation, as it should be high level enough to be understood by the core stakeholders
and be reused in future simulations.
It is created through interviews with subject matter experts, collecting data like procedures and results from similar exiting systems, and other sources of relevant data.
Problems like the data not being representative of the model, not being in the appropriate format or type, and containing errors must be handled before use.

The conceptual model also contains all of model parameters including the documented assumptions. 
It is defined to the level of detail given, project objective, performance measures, data availability, computer constraints, resource constraints.

\subsubsection{Step 3: Conceptual model Validation}
The conceptual model is the most important aspect of the simulation, thus its validation will be through.
The core method used to validate this model, is to discuss the it with core-stakeholders and subject matter experts.
This provides feedback as to the direction of the conceptual model, ensuring that it will answer the questions posed in the study.

\subsubsection{Step 4: Implement the Models}
The implementation of the simulation models must also be executed and documented in a way that allows other to replicate and repeat the process.
The artifacts created during this process must be verified to work correctly, this can be accomplished through test-cases and debugging.

\subsubsection{Step 5: Validate Implementation}
There is no completely definitive approach to validating the simulation,
however, the most definitive test of a simulations validity is established by closely looking at the outputted results compared to that from an actual system \cite{Law2005}.

This is done through:
\begin{itemize}
  \item \textbf{Results validation: } a comparable system is used to create results and compared with the results from the simulation for validation.
  \item \textbf{Face Validation: } experts are given output of the simulation model and checked to see if it is consistent with how they percieve the system should operate.
\end{itemize}

Further validation of the implementation can be accomplished with sensitivity analysis,
which is performed on the simulation to find the factors with the greatest impact on the performance and results.

\subsubsection{Step 6: Design, Conduct and Analyse Experiments}
For each of the configurations, decisions must be made about the time given to them, the number of independent runs to return statistically significant results.
At the end of this step, after the results have been analysed a decision must be made if additional experiments are to be run,
as either the results are inconclusive, or other aspects of interest have arisen.

\subsubsection{Step 7: Document and Present Results}
This step involves the presentation of the model to the core-stakeholders in a manner that describes the concept model, the simulation and the results.
This step is critical for the future re-use of the model, as is the detailed description of the validation process to promote credibility.


\subsection{Differences in methodology}
To produce a valid and credible simulation study is the goal of using this methodology.
However, this methodology has been created for industrial projects with of a larger scale; for instance the U.S.A. Department of Defence.
As this study is smaller in scale in time and effort that many other simulation projects, some of the procedures recommended in this method have been restricted and some removed.
The most significant difference to the methodology is the clear definition between decision-maker and simulation designer.
In this project these all refer to a single person, therefore meetings between these people are superfluous.
Other people in the project including subject-matter experts, core-stakeholders, simulation analysts consist of survey participants and
project supervisors, because the limits of the projects resources excludes employment of experts.
This may reduce the validity of the end model, but these restrictions have been made when only necessary,
and done so in a manner that attempts to minimise negative effects.


\section{Simulation artifacts}
We have used this methodology to create a simulation that is independent of the component model and system we want to simulate in this study.
This has been done to make the simulation reusable in different contexts in order to test if the conclusions drawn from this study are component model/system independent.
As such in this chapter we describe the independent parts of the simulation, and leave the dependent parts for chapter \ref{ubunutsimulation}.

The independent parts of this simulation include the problem definition, the conceptual model with it's component parts;
the user model, the solver model and the repository model.
The implementation of the simulation, the abstract configuration and what variable exist.

\subsection{Problem Definition and Conceptual Model}
To create our conceptual model, we must first precisely describe the problem;
The problem addressed in this entire study is that of the effects of component evolution.
The key question that are asked is
``What effect does using component resolution given a set of criteria have on a component system?''.
To answer this requires knowing about the criteria used to find the resolved systems, the repository where components are accessed,
and the user and their actions.
The conceptual model is then created from separate models, the user model, the solver model, and the repository model.

\subsection{User Model}
The user model involves many aspects, including the life-cycle of specific actions, the probability of actions being taken, and also the parameters of an action.
A user can typically execute many different types of actions, install, remove or upgrade a component, upgrade the entire system,
download a source for a component, change the status of a package, automatically remove package that are not necessary, or even format the system and start again.
In our abstraction of reality the user has two actions with the resolver, either to install a new package or to try upgrade the entire system.
These two action were selected as they represent the core interactions the user performs on the system.

%%%Update
Probably the most executed action by the user is the request to update the system.
This involves looking at the repository and trying to find newer versions of currently installed packages to replace the current versions.
This is done either because newer versions have increased functionality or have fixed bugs,
however can become quite complex as newer versions of component may conflict with other packages, therefore are not able to be installed.
The update action can happen at regular intervals as it is typically automated or part of a users routine.
These intervals can be quite quick, daily for many users, 
and they can be over an extended period of time, 
as with server administrators not wanting to change a potentially critical system.
In this abstraction, the core variable for a users update action is the cycle in which it occurs,
e.g. every 3 days the user updates.

%%%Install
Installation if the request a user performs to extend the functionality of the system they are using.
A user selects a package with the required functionality they desire, usually to complete a task,
then the resolver installs a system that allows that package to be used.
Determining the probability a user will select a component to be installed is difficult given the enormous amount of factors this relies on.
The users job, location, current tasks, previously installed software, favourite colour\ldots all may effect when and what package a user selects to install.
Given that all this information is impractical to simulate, we abstract this problem into the form of two questions;
what components may a user select to install and how likely would a user select to install these.
This is represented by a weighted list of components, where the weights represent popularity,
e.g. package ``A'' has a 10\% chance of being selected as the package to install, package ``B'' has a 5\% change \ldots


The next question is what is the probability that a user will install a package, and how many packages?
This is represented by a probability for the amount of packages that a user may install on a day,
e.g. they have a 80\% chance of installing nothing, a 15\% chance of installing one pace

A user model is then represented by 3 pieces of information,
\begin{enumerate}
  \item The cycle at which they update
  \item The probability any package will be installed
  \item The probability a user will select to install a package per day
\end{enumerate}


\section{Solver Model}
The solver selected to resolve the package dependencies is an important aspect of this simulation.
Throughout this thesis we have discussed the definition, implementation and extension of a component dependency resolver.
The core aspect we have focused on is the variable criteria that can be used to find different optimal solutions given the requirements of a system.
Given the users actions of update, and install have different objects the core varaibles for the solver are the criteria for these actions.


\section{Repository Model}
{}The repository model models the server which serves the packages to the client to be installed.
{}Superfluous aspects of the repository, like the protocol used to transfer the packages, are ignored in this simulation.
{}The model of the repository is complicated by the fact that our simulation takes into account what packages the repository had on a particular date.

%%%We create a repository for each different day

%%%The Ubuntu repository is selected because it has significant amount of users and a significant amount of components.

%%%The initial date is selected as it is after a major release, and the time length is the median system age from the user survey

%%%Analysis of the repository, summary from 

%%%This repository model differs from reality in the fact that we use all components, not just those available in the meta repository (ubuntu manacured)


\subsection{Strategies}
%%%How do users use different strategies when evolving a system when installing and updating their systems
A user interacts with a resolver to evolve a system by installing, removing or updating packages.
The way in which these interactions occur is usually related to the purpose of the system, and what the type of user.
For instance, a server administrator is less likely to install a component into a system as the system has only one task and if it is working their is no need to change it, 
however a desktop user will more likely install different packages because they use their system for many different tasks.
How a user updates their system is also different along these lines, server admins. will likely only update when absolutely necessary as if it is not broken why fix it.
Yet desktop users will update more frequently as they want the best system they can have, and new features or better performance are usually wanted.

As described in previous chapters, dependency resolvers often try to minimise change and maximise the versions.
These two objectives have been implemented in many different ways, how these interact with each other is the strategy a resolver employs.
For instance, the trendy strategy from the Mancoosi organisation describes the strategy to minimise the removed components above all other criteria,
this is a common strategy because removal of a component is seen as very risky.

\subsection{Consequences}
%%%The core consequences of using a strategy that we are looking at come from the dependencies between the strategy and the resulting metrics of critiera 

%%%Essentially what we want is a table with the strategies laid out in the columns and with how they effect different criteria in rows.

%%%This will show the dependence between the different strategies and what their effects are

%%%We have three control strategies that do not require criteria or user models, one that never updates, another updates daily and updates weekly.

%%%After this we can add criteria with different relationships, and installation strategies and observe the effects.

\subsection{Configuration}
%%%A configuration is the set of parameters of the simulation. What are these parameters which we must consider.
A configuration is the set of variables which define the parameters of the simulation.
How these variables are defined are derived from what goals of the simulation.
As the goal of this simulation is to look at different resolver criteria and user strategies,
these are the core changes that are made.
Given that we want to look at the effects of many different possible ways a system can evolve,
we also change the packages that are selected to be installed by the user.
The variables like, what repositories are used, and over what time period are seen as not being relevant to our eventual analysis,
therefore we do not change them and leave them static.

Given this simulation is looking at the effects of the strategies employed by users and resolvers on the component systems,
we must look at different resolvers, and different user strategies.
What packages the simulated user selects to install and 

%%%The criteria for updating and installation we are testing
The most significant variable in the configuration is the criteria used by the solver to find optimum solutions. 
As there are two separate actions the user can make, updating and installing, each of these can have different criteria associated with them.
This is necessary because the optimum solution for these two actions should be different,
as a user installing will probably not want to update their entire system when trying to install a single package.

%%%We are changing the distributions of user installaion, and the period between updates
The user installs different amount of packages per day, and updates at different intervals. 

%%%We are selecting different packages to install
We are selecting the packages to install that are different.

%%%The repository over which it runs changes over time
Time, We have decided not to 





\section{Simulation Validation}
%%%With the methodology there are many pionts at which we validate individual parts/models, and their overall composition.
%%%The main validation method is the inviewing of different stakeholders, this for our method was discussions with supervisors, at conferences, and throught the survey.


\section{Simulation implementation}
%%%Here we describe how our simulation is implemented, specifics that are not previously mentioned, and the variables not yet defined

%%%Preprocessing of the weighted components, removing all packages that are unable to be accomplished (e.g. skype)
%%%When createing the CUDF files it removes install requests that are not in the system (e.g. if chromium was added to the repository in 2010 and it is requestied in 2009, it is just ignored.)

%%%What happens when a install is required that is then not able to be accomplished.

%%%Scripts and such are in the appendix, some code is here though, particularly interesting or critical code.

\section{Conclusions}
%%%Discuss the overall conclusions. Bullet point the points most surprising, and useful for further study.

